{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig33N7IHYTKV"
      },
      "source": [
        "# Early-stop encoding\n",
        "\n",
        "The first part of this notebook is based on the [build notebook](https://github.com/futo-org/whisper-acft/blob/main/finetune.ipynb) for `whisper-acft`. It creates a variant of Whisper more [robust to an encoder that stops early](https://github.com/futo-org/whisper-acft?tab=readme-ov-file#motive-and-explanation-for-anyone-uninitiated).\n",
        "\n",
        "The `whisper-acft` build notebook is licensed under the MIT license:\n",
        "<details><summary>MIT License</summary>\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2024 FUTO Organization\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RV_029B512y",
        "outputId": "8b118403-50c2-4623-d5f0-d9da17ea9c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.4.1 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "11424360c6894eef892cffff0f2d02d6",
            "a30b25ed607e442aaaae1da96cfc8fe4",
            "0bd872e7247049a5b4fadc57f9cd32ee",
            "a7c578a0e69146d3b5c75d53e4a225a3",
            "ffb1b05b24dd442788c29a47196ff83e",
            "6f80d5ee791647918d691a7506b1b6b5",
            "2c8b6d0b734e45bd99673a89b95597df",
            "5d6e0f0da40b49e9ac71bf30ad89f0f1",
            "48d89215af1449d9aa4837a7d72eb747",
            "7d49033f6cfa49bf979de9fdcfe219e7",
            "8370637b3a654933b33fa73f06ba5e8a",
            "9e7e861ab78e4239a73aa31c0186343d",
            "409dc4ce6e38455fa740bd764abb77a9",
            "5341f8cf7d2145499e9491ae6985d4dc",
            "631f8b5faae04e4cb90faf8233de9ebb",
            "d1046e2c049043eeb0b89273d0202f7d",
            "4d49c74f861a47d0b4351feae527d5fc",
            "b90896fa2b5847af942c29307a418fe2",
            "6d7c97b4cdfc436caa0b7a9b229ad72c",
            "51dd52013dd8409fad7ddc7d93a91276",
            "928f754a226a49a3bf4574d05bd579f0",
            "e4b1a65d3ff340a1bfe786b4831cc490",
            "003a067cff2540cc8195faa83346befe",
            "805d48ee28434df09a9669f11b523e58",
            "c8a06db1ca804d0f871fe1db2b3fa2a0",
            "a2a98e0cb36f46b99e41a5da71382e7a",
            "f2315f9f0f6942c9a9d84c5e7437e197",
            "cb94912bda0c4486a675bdea98fa355f",
            "68c33dd41b2446de8d7b834d6ee0cc3d",
            "259da823ae4146a0ba3d07cd61283e36",
            "ce1a67c37d1041878aaa621889ac78ce",
            "2a5e04b2c0744290a2950c6e1e672714",
            "5da4930fe9174d9690d1c61a24bc6469",
            "78bc471e914d44e0b9f901d7c8210eff",
            "dcd9a9b41b4b46bab7d19a0cc9c96eba",
            "9cdc832d11f748eda802b2172e40088c",
            "afff3f98438c4308ad52325706d5043b",
            "3cf9f915d54049ec908ed6eb8aa4baca",
            "c757dc0183354d7a954985d6a5c684d1",
            "7a6affcb15d74eb5928fa00cecac3afc",
            "f108d35a1a0242498628fe0947dc03bb",
            "54e12e538a9e4090afb0f177dd89e663",
            "e0d82edf9f9c45a78ec0e3b9e14a1c5b",
            "6d4bc9bf6f414a5f88db27206433f6c8",
            "e9496db797a346eebda36905100595b1",
            "36118f96fa964df39e602e5eca6f3999",
            "6745d7fb84644c119c6db9bd5caab455",
            "5f61e9ee10c5427794980b4c05b9c8d1",
            "28803f5eb25d41ec9b4d264119c3a276",
            "9deaeef5294f42a59c5ed92b00ac333e",
            "336e4ced31954f66bab02f7bc258b312",
            "bdd56616fe3a45f19b38b083f16b464c",
            "736fd825981f4922a35e93fff7b71436",
            "0fd065e67af446f493554e7a1405118a",
            "b1d05f93d4f545d1bf110c7d8239736f",
            "595dd6ac371e49d595a60dc7d41569ad",
            "354dd8d73a9b4991af1caa37f3b0337f",
            "106207d41f734a348143ef219e563ab4",
            "ba2b2eb914234e3591d52cdaf561edc8",
            "cace2bcffbe9435ea41f263c4cca1650",
            "9018f8e0e9124f93bb081e5dca0f7bdc",
            "51f7a3d2cb7744b5a2ffd63a074a4a6b",
            "39e036368b7d47b2861692a33c1f8d8d",
            "68f77267ab1c491a99c9e7287481e0e9",
            "0cd3bf7eb27b4ed8b1c9e0f0b86fd7c5",
            "144596f8aaa84d7ea0163b01b3ebd1fd",
            "91816269aaea4d028af7c2b060220eed",
            "2ca950ef957a4a93a7ffc657915f4637",
            "37ace24790444698b752c4968cd57346",
            "4ce2fb8b0833489798e022601182530c",
            "9c38caa03b3844b48631c0dcc310eab5",
            "8c0e4d650dd346f2bbc172996e7b87d8",
            "d0ac778cbf8c44e392910e0f1c95ec81",
            "1206a503e9564738a14d4a9d4285c74c",
            "58c868b18269426186b22cb2251c20d4",
            "929ccf3a803f434485d232d3a774a261",
            "b31e6d5ebb2b4020b3d906a0d2cae2ea",
            "bb03d54238a44541968dc8617081c898",
            "502092bb386c4b6a8dca1d52a7f7abed",
            "20b2b12b877a4c83a87145aea1aea485",
            "395611b4037b47978c02ec24558d115a",
            "343cab84fabf4dc2a24909c68fce9787",
            "b9d57344050b4c40bc8203f02d227699",
            "076c81f2816343738e016caeb0cc3d0d",
            "59f1f07f18e04f20aacb7a3ae4e9c785",
            "fffdaeb03a5f444c813f0a5d8f695275",
            "c900c666b2ae434585ac1a46af8f61f8",
            "4626d82323e04abea9568350663770f1",
            "e3dfd8fbb52040b1ae45f8233250d18c",
            "e32d9d601608434684a5d92084ebd771",
            "9fbb57c244c54c748e6ec0fd4244abd4",
            "059a8bc00e624e94a7a5b8d812929727",
            "35d4218f504543b3a2d0b63993051be6",
            "5b73d162c5464dcc8c301d6540217579",
            "090db7185c9549ba974bf9fa197d0b87",
            "114f5e5d913a4c8c898d35cd25a7a091",
            "23ee3e4bdd5046e8a187408b9fd709b5",
            "2ffaff647f9b494da09523525a6ab8a2",
            "820c9a6e8ac546aa9bdd8470e4bf6b0b",
            "25de75a6a6a849909df8f9964bbb3186",
            "d697e74ce5754ebca44cd0004d432e74",
            "9e9aa5f1f62d43a2aa1bac3a7a370605",
            "efd487ca0e0e4430b35cf4207eb84f85",
            "03fc62205ec94f2b806028ccd64d161d",
            "db5d106524be442baa9289544aa2e14b",
            "95ca694f743041c497932b40257ea93d",
            "6abc44816c0f41cc9c79e77abf6aed68",
            "bdb764b247104c7e97a87becb7bac18b",
            "1c3c094dbe6547aebd81da1994b21444",
            "4cfff529177b4c2dba76f5e4b87f85e4",
            "7c6dd5ac3b1d4da1b8d4409aabb39b5f",
            "f81113489325466e9ac0e1f927a6f3e5",
            "d727170bdfc6453a8980ad5108febd92",
            "3a57b6cb577344459d3d9dc3a231d8c2",
            "b423b56bc2c7448381285e77bc557214",
            "8b6f093b8f294fb89c6cddc83bda94fc",
            "211dab2f2e474fa0b9342c8bb81b1b05",
            "66a3a38df40c4755aa5071ddfdcd25f9",
            "3421b4bd291d4c4f93591de45683b776",
            "b7e5e4a3f0e44209824be75d6c13c096",
            "c76a2ec583a640a58d1a8e4d3e2f383f"
          ]
        },
        "id": "ylm1ZBQNZH8_",
        "outputId": "77eba943-d58e-4ae0-a5a2-dbefedd101b3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11424360c6894eef892cffff0f2d02d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/13.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e7e861ab78e4239a73aa31c0186343d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "fleurs.py:   0%|          | 0.00/12.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "003a067cff2540cc8195faa83346befe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train.tar.gz:   0%|          | 0.00/1.73G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78bc471e914d44e0b9f901d7c8210eff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "dev.tar.gz:   0%|          | 0.00/143M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9496db797a346eebda36905100595b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test.tar.gz:   0%|          | 0.00/349M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "595dd6ac371e49d595a60dc7d41569ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train.tsv:   0%|          | 0.00/2.06M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91816269aaea4d028af7c2b060220eed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "dev.tsv:   0%|          | 0.00/181k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb03d54238a44541968dc8617081c898",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test.tsv:   0%|          | 0.00/457k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3dfd8fbb52040b1ae45f8233250d18c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25de75a6a6a849909df8f9964bbb3186",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c6dd5ac3b1d4da1b8d4409aabb39b5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset, Audio\n",
        "dataset_fr = load_dataset('google/fleurs', 'fr_fr', split='train')\n",
        "\n",
        "audio_feature = Audio(sampling_rate=16_000)\n",
        "dataset_fr = dataset_fr.cast_column('audio', audio_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otmxn5yWaRKw"
      },
      "source": [
        "## Model setup\n",
        "\n",
        "Next, create two models: One to be trained and one to use as a refrerence. To try to keep the output as consistent as possible, we'll use the output of `model_base` as the expected output of `model_train`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305,
          "referenced_widgets": [
            "2adec94e656c42c8858ab9c721ce27d7",
            "33fd50473c4048a0b16a44710fd29bdc",
            "397baec41f6a4a9eb0f37df626fcb0bc",
            "aacaddc20f22490e854b19d1c9ddef9c",
            "19cf3389474a48698a92832acee3f18f",
            "580dc0add5554e6cb2dddae2de0b1930",
            "9882ddd4adb94c35a49b0c9ccb5e2e05",
            "09aa11f1ab4548269ca3fa7b55602043",
            "a43abd99dc4b4d50a1d37daad26da8dd",
            "da1041d342934bcebad5d2eaf8339d82",
            "36fd2666a3a2471a837438410700b312",
            "b4e8aa4e3e4241558fca50c3822f878c",
            "6db171d8bbb04583a3ca7bfe880e717d",
            "d1ee213274a84336a6b6db12c0439a32",
            "adadfa51380245998d64477dc7518231",
            "2bafd2a7fe9e413d932370c71b50c7ef",
            "35d2cd81332042b5a722f66539429513",
            "305f5b158d5a4172aa7c68a9f948ff9c",
            "d291796f399b4b00a474af019ff16291",
            "f97076eef7134d1996cf841c0ee29575",
            "7ec76f3b429c436dab661cab2acd75dd",
            "8d7ef8017dff4dfeb65763505a15521f",
            "e28a670a4fff4bf9b54653062926a747",
            "496b65a085ee48f7b38cd0ccc3f8c92a",
            "60e145eccfb24126b15987487f982b51",
            "9aca1f1e0e3b4285823c36f27e74f343",
            "44694d5ac2d74cc59933ad3c94ae7c6d",
            "60bf454bb0f44d83a024ff8853d3c790",
            "345ba32482574d1085a4f7a8ff1f92b4",
            "5d0608f4fd504c82a612dcd251f93f24",
            "691e91fee7044205a4f3d006876f8dd6",
            "5961316d0035449ab25f51fcc6593c60",
            "fe9f4c1a578c4e7a99339c8ca362807a",
            "5483dcc6e7f8446fbdf40e43acf85303",
            "cb0e7dec3f8d40fe8580c3e47d8595fa",
            "d3fbb333aed440b88061d195f2283ea8",
            "5ffeb8f8a79d4a68b9e085c5a2ac2db7",
            "49e71b73b773436d9cf1d49073cc9f54",
            "f4e5ba25a5ea482f9afea5a9c1cca51f",
            "ddb879a1eaa34af298efbcb08c6c8cbc",
            "8704abdb0ea34e3d9c0a2e4638f0c562",
            "f00040648afc4d49899dd7b14d72acc2",
            "bb6e4343c5b44d82ae8277a67349680d",
            "d5c459fe58ca4653a2ac4ba807f92c04",
            "6c8be2bc89614dff8fe97fc321b4c3ee",
            "e2f186b5ef5c4a6e959dd88e16791221",
            "bc833dbb11564e24bb77b024963732af",
            "ab198f92c218450f808bb91fc2312246",
            "f4ef1d2453c5477e9c41662ed26a7830",
            "0e2fb1039f0d46559c0e9d13d3c1899d",
            "1310feab8b3f4424a5b5c9d5d38802ec",
            "66777ae5da5f4616acb1e3ae247a3dc0",
            "d575a57f365b4fb4b5e1198ff8cbaf4a",
            "d2eacf952bab4dc18c8e85284d6986db",
            "40313219d9774f3791972231ac17b597",
            "276a68431bf148acabf621a65f42d70f",
            "e2e457f67b914037a50ba239d05a4d54",
            "74c132f9fe094fdeb9a40500ed631318",
            "5ea4640bfd29456f882e008fde609976",
            "cea9755b57e34ac582dd218030fbae40",
            "281e4ad469254ed8914f860caea86ba6",
            "4ab1fa6b92d848ec9b60b4088f6c8cdc",
            "c4c3f86ceef049f3b7d6ddce3e55b397",
            "647748b526d84bcf8df3f68eececc4e6",
            "7e2e6b777952497c86b1740a25a3518e",
            "6504a871717944368599e3790364cf5e",
            "4d6abd0b8bde4970a4b5b248c3befb65",
            "5bfce4238a854cec8a0ebc7563ab1466",
            "e73a4706663c44c5b5dbfa40ef73176a",
            "d79a7608163347d69cd44fc126932f4e",
            "12aa0fbf27b24354b20f2e57c02da162",
            "e3a83bc8d51646f5b0948b25af11d227",
            "be164dc3c4b34d0a9af2f831bf2d47e0",
            "4f76d415bb6d488eb67c083c21d3d5a2",
            "1bb5faeb43eb41598b7cb553099d0667",
            "000044775b1f49f8a11e60e5416df349",
            "c5a881b74f804579a0de940910f86297",
            "fd54e14b28264c19800a891e1c5f763d",
            "b75809adbbc249d9a8fbf0d8796254fd",
            "1b259bcf93574088821f5c6433cf5623",
            "d9fc5fb5ed1049549dbe5c48e4d2acb8",
            "0f2dccd4f7bd4c5ca2eded6080ef3822",
            "c07b7c80b4294f358d7bb7e8e273d581",
            "9972321dede143afa4772c4ea4df8a43",
            "444dc1f65ba8410d9c67e75a73fe673c",
            "39576e248ce54682a617643f2a9d947c",
            "54035b97bb2941a3b8af459c9026abe9",
            "a4bf322c91004959adbb5e53d4d06084",
            "fdfedeeedfc244578d20f67901ac832c",
            "97929a40a7f3476cb41d8d2029c72b13",
            "e095966878f34e0eb8b24eb7707e9576",
            "eb626516bbdd4bf49dc4c64732d69d45",
            "a22341bcfea44498a74cb09df9ef5ec6",
            "5018ffbb6e494b99b5b5da45d4256f60",
            "5fa56471c8404516b43732f1e9391991",
            "044faa858eeb46329439ab91ce284a61",
            "70c0b4822d014825a4a32e4803afd1b0",
            "9d598e6925564e79b370922a84216131",
            "4e56620da0564341a94424f33914fe27"
          ]
        },
        "id": "pNeijGwl6Ldz",
        "outputId": "e78926e5-b76a-48d9-d120-01c9c5f661cf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2adec94e656c42c8858ab9c721ce27d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4e8aa4e3e4241558fca50c3822f878c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/290M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e28a670a4fff4bf9b54653062926a747",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/339 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5483dcc6e7f8446fbdf40e43acf85303",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c8be2bc89614dff8fe97fc321b4c3ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "276a68431bf148acabf621a65f42d70f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d6abd0b8bde4970a4b5b248c3befb65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd54e14b28264c19800a891e1c5f763d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdfedeeedfc244578d20f67901ac832c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import WhisperModel, WhisperTokenizer, WhisperProcessor\n",
        "\n",
        "# TODO: Change model_name to match the name of the model to update (e.g. to personalizedrefrigerator/whisper-base-fr)\n",
        "whisper_mode = 'base'\n",
        "model_name = f'personalizedrefrigerator/whisper-{whisper_mode}-fr'\n",
        "model_train = WhisperModel.from_pretrained(model_name).cuda().train()\n",
        "model_base = WhisperModel.from_pretrained(model_name).cuda().eval()\n",
        "processor = WhisperProcessor.from_pretrained(model_name, language='french', task='transcribe')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gF18nNlcAIy"
      },
      "source": [
        "## Fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfUBTmVRgNfr"
      },
      "outputs": [],
      "source": [
        "ds = dataset_fr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzqOsTXCaOdh",
        "outputId": "01a03099-7b56-4a95-d767-0ae3f7f3d9a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<|startoftranscript|>',\n",
              " '<|fr|>',\n",
              " '<|transcribe|>',\n",
              " '<|notimestamps|>',\n",
              " 'Il',\n",
              " ' s',\n",
              " '�',\n",
              " '�',\n",
              " 'agit',\n",
              " ' d',\n",
              " '�',\n",
              " '�',\n",
              " 'une',\n",
              " ' ent',\n",
              " 'ité',\n",
              " ' très',\n",
              " ' complex',\n",
              " 'e',\n",
              " ' qui',\n",
              " ' consiste',\n",
              " ',',\n",
              " ' selon',\n",
              " ' un',\n",
              " ' modèle',\n",
              " ' de',\n",
              " ' Boh',\n",
              " 'r',\n",
              " ' simpl',\n",
              " 'ifi',\n",
              " 'é',\n",
              " ',',\n",
              " ' en',\n",
              " ' un',\n",
              " ' no',\n",
              " 'y',\n",
              " 'au',\n",
              " ' central',\n",
              " ' orb',\n",
              " 'ité',\n",
              " ' par',\n",
              " ' des',\n",
              " ' élect',\n",
              " 'rons',\n",
              " ',',\n",
              " ' un',\n",
              " ' peu',\n",
              " ' comme',\n",
              " ' les',\n",
              " ' plan',\n",
              " 'è',\n",
              " 'tes',\n",
              " ' en',\n",
              " ' orb',\n",
              " 'ite',\n",
              " ' autour',\n",
              " ' du',\n",
              " ' sole',\n",
              " 'il',\n",
              " ' —',\n",
              " ' c',\n",
              " 'f',\n",
              " '.',\n",
              " ' illustration',\n",
              " '�',\n",
              " '�',\n",
              " '1',\n",
              " '.',\n",
              " '1',\n",
              " '.',\n",
              " '<|endoftext|>']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_sample(example):\n",
        "    waveform = example['audio']['array']\n",
        "    sampling_rate = example['audio']['sampling_rate']\n",
        "    assert sampling_rate == 16_000\n",
        "\n",
        "    input_features = processor(\n",
        "        waveform, sampling_rate=sampling_rate, return_tensors='pt'\n",
        "    ).input_features\n",
        "    input_ids = processor.tokenizer.encode(example['raw_transcription'])\n",
        "    return {\n",
        "        'length': len(waveform) / sampling_rate,\n",
        "        'input_features': input_features,\n",
        "        'input_ids': input_ids\n",
        "    }\n",
        "\n",
        "# Test\n",
        "[processor.tokenizer.decode(i) for i in get_sample(ds[1])['input_ids']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BYxybfAaipJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "\n",
        "# Note: Mostly copied from https://github.com/futo-org/whisper-acft/blob/main/finetune.ipynb\n",
        "#       See above for license and other information.\n",
        "\n",
        "def compute_partially_encoder(model, data, n_audio_ctx):\n",
        "    \"\"\"\n",
        "        Computes hidden states for the given model with only a partial run of the encoder.\n",
        "\n",
        "        Parameters:\n",
        "        - model: The model.\n",
        "        - data: Input features to the model.\n",
        "        - n_audio_ctx: Constant slightly larger than the recording length (in 1 unit / 50s). Set to 1500 to use the full recording. See https://github.com/futo-org/whisper-acft/issues/6#issuecomment-2290093422.\n",
        "    \"\"\"\n",
        "    diffy = 2 * n_audio_ctx - data.shape[2]\n",
        "    if diffy > 0:\n",
        "        data = nn.functional.pad(data, [0, diffy, 0, 0, 0, 0], 'constant', 0.0)\n",
        "    elif diffy < 0:\n",
        "        data = data[:,:,:diffy]\n",
        "\n",
        "    # Default encoding -- the full audio\n",
        "    if n_audio_ctx == 1500:\n",
        "        return model.encoder(data).last_hidden_state\n",
        "\n",
        "    input_embeds = nn.functional.gelu(model.encoder.conv1(data))\n",
        "    input_embeds = nn.functional.gelu(model.encoder.conv2(input_embeds))\n",
        "    input_embeds = input_embeds.permute(0, 2, 1)\n",
        "\n",
        "    embed_pos = model.encoder.embed_positions.weight[:n_audio_ctx]\n",
        "\n",
        "    hidden_states = input_embeds + embed_pos\n",
        "    hidden_states = nn.functional.dropout(hidden_states, p=model.encoder.dropout, training=model.encoder.training)\n",
        "\n",
        "    for idx, encoder_layer in enumerate(model.encoder.layers):\n",
        "        to_drop = False\n",
        "        if model.encoder.training:\n",
        "            dropout_probability = torch.rand([])\n",
        "            if dropout_probability < model.encoder.layerdrop:\n",
        "                to_drop = True\n",
        "\n",
        "        if to_drop:\n",
        "            layer_outputs = (None, None)\n",
        "        else:\n",
        "            if model.encoder.gradient_checkpointing and model.encoder.training:\n",
        "                layer_outputs = model.encoder._gradient_checkpointing_func(\n",
        "                    encoder_layer.__call__,\n",
        "                    hidden_states,\n",
        "                    None,\n",
        "                    None,\n",
        "                    False,\n",
        "                )\n",
        "            else:\n",
        "                layer_outputs = encoder_layer(\n",
        "                    hidden_states,\n",
        "                    None,\n",
        "                    layer_head_mask=None,\n",
        "                    output_attentions=False,\n",
        "                )\n",
        "\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "    hidden_states = model.encoder.layer_norm(hidden_states)\n",
        "    return hidden_states\n",
        "\n",
        "\n",
        "def compute_hidden_state_loss(model_train, model_base, optimizer, criterion, example):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    n_ctx = int(round((1500.0 / 30.0) * example[\"length\"] ))\n",
        "\n",
        "    extra_ctx = torch.randint(-min(64, n_ctx // 3), min(64, n_ctx // 3), (1,)).item()\n",
        "    n_ctx += extra_ctx\n",
        "\n",
        "    input_features = example[\"input_features\"].cuda()\n",
        "    input_ids = torch.tensor([example[\"input_ids\"]], dtype=torch.long).cuda()\n",
        "\n",
        "    encoder_hidden_states_partial = compute_partially_encoder(model_train, input_features, n_ctx)\n",
        "    output_partial = model_train.decoder(\n",
        "        input_ids=input_ids,\n",
        "        encoder_hidden_states=encoder_hidden_states_partial,\n",
        "        output_hidden_states=True\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden_states_full = compute_partially_encoder(model_base, input_features, 1500)\n",
        "        output_full = model_base.decoder(\n",
        "            input_ids=input_ids,\n",
        "            encoder_hidden_states=encoder_hidden_states_full,\n",
        "            output_hidden_states=True\n",
        "        )\n",
        "\n",
        "    loss = criterion(\n",
        "        #output_partial.hidden_states[-1],\n",
        "        #output_full.hidden_states[-1]\n",
        "        torch.cat(output_partial.hidden_states, 0),\n",
        "        torch.cat(output_full.hidden_states, 0)\n",
        "    )\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MXMoMKbf35D"
      },
      "source": [
        "Next, enter the training loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4RCVEdHcjUX",
        "outputId": "99042e7d-dabe-49c6-afa4-ae2c7ca57d80"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3193 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "Epoch 0, Loss: 0.03439435735344887: 100%|██████████| 3193/3193 [06:32<00:00,  8.14it/s]\n",
            "Epoch 1, Loss: 0.042581308633089066: 100%|██████████| 3193/3193 [06:26<00:00,  8.27it/s]\n",
            "Epoch 2, Loss: 0.022116176784038544: 100%|██████████| 3193/3193 [06:26<00:00,  8.27it/s]\n",
            "Epoch 3, Loss: 0.017987575381994247: 100%|██████████| 3193/3193 [06:25<00:00,  8.28it/s]\n",
            "Epoch 4, Loss: 0.013689461164176464: 100%|██████████| 3193/3193 [06:26<00:00,  8.26it/s]\n",
            "Epoch 5, Loss: 0.02007947489619255: 100%|██████████| 3193/3193 [06:27<00:00,  8.25it/s]\n",
            "Epoch 6, Loss: 0.019504878669977188: 100%|██████████| 3193/3193 [06:25<00:00,  8.28it/s]\n",
            "Epoch 7, Loss: 0.01682526059448719: 100%|██████████| 3193/3193 [06:26<00:00,  8.26it/s]\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Note: Mostly copied from https://github.com/futo-org/whisper-acft/blob/main/finetune.ipynb\n",
        "#       See above for license and other information.\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model_train.parameters(), lr=1e-7)\n",
        "\n",
        "\n",
        "writer = SummaryWriter()\n",
        "writer.add_text(\"name\", f\"{model_name} v3\")\n",
        "\n",
        "num_length = 0\n",
        "step = 0\n",
        "for epoch in range(8):\n",
        "  pbar = tqdm(ds.shuffle(seed=epoch))\n",
        "  for example in pbar:\n",
        "    example = get_sample(example)\n",
        "    if example[\"length\"] > 29.0: continue\n",
        "\n",
        "    loss = compute_hidden_state_loss(model_train, model_base, optimizer, criterion, example)\n",
        "    step += 1\n",
        "    num_length += example[\"length\"]\n",
        "\n",
        "    writer.add_scalar(\"loss/train\", loss.item(), step)\n",
        "    writer.add_scalar(\"length/train\", num_length, step)\n",
        "    writer.add_scalar(\"epoch/train\", epoch, step)\n",
        "\n",
        "    pbar.set_description(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "206598dc996a4e53b42839d7b83721db",
            "40cc98bdab7d48be992bc54aec13c870",
            "62cdacb8df664b9eaaae2f288b35e5db",
            "808674c965ea49beaf4e90a3ecb07375",
            "d5c0562b4bfc42cc8ff81c3913a4b397",
            "16cc10de2cd645688f22b73373882789",
            "bc80568500864ec888d113831e761cc8",
            "34267202c4c94dde8ff5d87f1bc9d36f",
            "db43ff9a3bd34eaba0d7e30425e0475e",
            "1ce2bc8952a44f1eb09c47c33f3ab24e",
            "966877198a2c460b987a57eb181a11b0"
          ]
        },
        "id": "dP_9YLfyhMk_",
        "outputId": "c8467fce-cb87-4fdf-9fdf-eeb3da808b1b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "206598dc996a4e53b42839d7b83721db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/3.75k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('final-model/tokenizer_config.json',\n",
              " 'final-model/special_tokens_map.json',\n",
              " 'final-model/vocab.json',\n",
              " 'final-model/merges.txt',\n",
              " 'final-model/normalizer.json',\n",
              " 'final-model/added_tokens.json')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import WhisperForConditionalGeneration\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name).eval().cpu()\n",
        "model.model = model_train.eval().cpu()\n",
        "\n",
        "model.save_pretrained('final-model')\n",
        "processor.tokenizer.save_pretrained('final-model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev5gYR3rgoWw"
      },
      "source": [
        "## Testing it!\n",
        "\n",
        "To verify that the model still works, log the model's output on the first sample in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHDnsucigpeH",
        "outputId": "fd97fd30-8b0d-4892-d844-980397c26753"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "It is strongly recommended to pass the `sampling_rate` argument to `WhisperFeatureExtractor()`. Failing to do so can result in silent errors that might be hard to debug.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, 50259], [2, 50359], [3, 50363]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[\"Quand la capsule rentrera dans l'atmosphère terrestre, vers 5 heures du matin, par de l'Est, elle offrira un spectacle lumineux spectaculaire aux habitants du nord de la Californie, de l'Oregon, du Nevada et de l'Utah.\"]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_data = next(iter(dataset_fr))\n",
        "\n",
        "input_ids = processor(\n",
        "    sample_data['audio']['array'], return_tensors='pt'\n",
        ").input_features\n",
        "output_ids = model.generate(inputs=input_ids)\n",
        "processor.batch_decode(output_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0e9GSFSfDsr"
      },
      "source": [
        "# Model conversion\n",
        "\n",
        "Next, we need to convert the model into a format usable by Joplin. This next step converts the model from PyTorch to GGML. Note that this section has been copied and modified from the Joplin `whisper_vocab_cleanup.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz5y6PdM5Qei",
        "outputId": "15d534e5-d166-4da0-8efb-e13b4b12e5fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'whisper-github'...\n",
            "remote: Enumerating objects: 828, done.\u001b[K\n",
            "remote: Counting objects: 100% (370/370), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 828 (delta 333), reused 301 (delta 301), pack-reused 458 (from 2)\u001b[K\n",
            "Receiving objects: 100% (828/828), 8.26 MiB | 16.58 MiB/s, done.\n",
            "Resolving deltas: 100% (496/496), done.\n",
            "Cloning into 'whisper.cpp'...\n",
            "remote: Enumerating objects: 16341, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 16341 (delta 6), reused 13 (delta 4), pack-reused 16314 (from 2)\u001b[K\n",
            "Receiving objects: 100% (16341/16341), 19.39 MiB | 16.43 MiB/s, done.\n",
            "Resolving deltas: 100% (11348/11348), done.\n",
            "Note: switching to 'v1.7.4'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 8a9ad78 release : v1.7.4\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/openai/whisper whisper-github\n",
        "!git clone https://github.com/ggerganov/whisper.cpp\n",
        "!cd whisper.cpp && git checkout v1.7.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`whisper.cpp` needs a patch in order to successfully convert the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUMzKNCmJfq0"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "# Patch convert-h5-to-ggml to work with more recent model versions\n",
        "conversion_script_path = Path('whisper.cpp/models/convert-h5-to-ggml.py')\n",
        "conversion_script_content = conversion_script_path.read_text()\n",
        "with open(conversion_script_path, 'w') as conversion_script:\n",
        "    bad_if_statement = 'if \"max_length\" not in hparams:'\n",
        "    replaced_if_statement = 'if \"max_length\" not in hparams or hparams[\"max_length\"] == None:'\n",
        "    conversion_script.write(conversion_script_content.replace(bad_if_statement, replaced_if_statement))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the patch is applied, the model can be converted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6eeyWNgdw8f",
        "outputId": "4525143e-67ea-4553-fb84-99bb6fadb45c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-03-25 19:12:12.046308: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742929932.071602   14503 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742929932.078064   14503 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "model.encoder.conv1.weight  ->  encoder.conv1.weight\n",
            "encoder.conv1.weight 3 (512, 80, 3)\n",
            "model.encoder.conv1.bias  ->  encoder.conv1.bias\n",
            "  Reshaped variable:  encoder.conv1.bias  to shape:  (512, 1)\n",
            "encoder.conv1.bias 2 (512, 1)\n",
            "  Converting to float32\n",
            "model.encoder.conv2.weight  ->  encoder.conv2.weight\n",
            "encoder.conv2.weight 3 (512, 512, 3)\n",
            "model.encoder.conv2.bias  ->  encoder.conv2.bias\n",
            "  Reshaped variable:  encoder.conv2.bias  to shape:  (512, 1)\n",
            "encoder.conv2.bias 2 (512, 1)\n",
            "  Converting to float32\n",
            "model.encoder.embed_positions.weight  ->  encoder.positional_embedding\n",
            "encoder.positional_embedding 2 (1500, 512)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.self_attn.k_proj.weight  ->  encoder.blocks.0.attn.key.weight\n",
            "encoder.blocks.0.attn.key.weight 2 (512, 512)\n",
            "model.encoder.layers.0.self_attn.v_proj.weight  ->  encoder.blocks.0.attn.value.weight\n",
            "encoder.blocks.0.attn.value.weight 2 (512, 512)\n",
            "model.encoder.layers.0.self_attn.v_proj.bias  ->  encoder.blocks.0.attn.value.bias\n",
            "encoder.blocks.0.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.self_attn.q_proj.weight  ->  encoder.blocks.0.attn.query.weight\n",
            "encoder.blocks.0.attn.query.weight 2 (512, 512)\n",
            "model.encoder.layers.0.self_attn.q_proj.bias  ->  encoder.blocks.0.attn.query.bias\n",
            "encoder.blocks.0.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.self_attn.out_proj.weight  ->  encoder.blocks.0.attn.out.weight\n",
            "encoder.blocks.0.attn.out.weight 2 (512, 512)\n",
            "model.encoder.layers.0.self_attn.out_proj.bias  ->  encoder.blocks.0.attn.out.bias\n",
            "encoder.blocks.0.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.self_attn_layer_norm.weight  ->  encoder.blocks.0.attn_ln.weight\n",
            "encoder.blocks.0.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.self_attn_layer_norm.bias  ->  encoder.blocks.0.attn_ln.bias\n",
            "encoder.blocks.0.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.fc1.weight  ->  encoder.blocks.0.mlp.0.weight\n",
            "encoder.blocks.0.mlp.0.weight 2 (2048, 512)\n",
            "model.encoder.layers.0.fc1.bias  ->  encoder.blocks.0.mlp.0.bias\n",
            "encoder.blocks.0.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.fc2.weight  ->  encoder.blocks.0.mlp.2.weight\n",
            "encoder.blocks.0.mlp.2.weight 2 (512, 2048)\n",
            "model.encoder.layers.0.fc2.bias  ->  encoder.blocks.0.mlp.2.bias\n",
            "encoder.blocks.0.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.final_layer_norm.weight  ->  encoder.blocks.0.mlp_ln.weight\n",
            "encoder.blocks.0.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.final_layer_norm.bias  ->  encoder.blocks.0.mlp_ln.bias\n",
            "encoder.blocks.0.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.self_attn.k_proj.weight  ->  encoder.blocks.1.attn.key.weight\n",
            "encoder.blocks.1.attn.key.weight 2 (512, 512)\n",
            "model.encoder.layers.1.self_attn.v_proj.weight  ->  encoder.blocks.1.attn.value.weight\n",
            "encoder.blocks.1.attn.value.weight 2 (512, 512)\n",
            "model.encoder.layers.1.self_attn.v_proj.bias  ->  encoder.blocks.1.attn.value.bias\n",
            "encoder.blocks.1.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.self_attn.q_proj.weight  ->  encoder.blocks.1.attn.query.weight\n",
            "encoder.blocks.1.attn.query.weight 2 (512, 512)\n",
            "model.encoder.layers.1.self_attn.q_proj.bias  ->  encoder.blocks.1.attn.query.bias\n",
            "encoder.blocks.1.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.self_attn.out_proj.weight  ->  encoder.blocks.1.attn.out.weight\n",
            "encoder.blocks.1.attn.out.weight 2 (512, 512)\n",
            "model.encoder.layers.1.self_attn.out_proj.bias  ->  encoder.blocks.1.attn.out.bias\n",
            "encoder.blocks.1.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.self_attn_layer_norm.weight  ->  encoder.blocks.1.attn_ln.weight\n",
            "encoder.blocks.1.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.self_attn_layer_norm.bias  ->  encoder.blocks.1.attn_ln.bias\n",
            "encoder.blocks.1.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.fc1.weight  ->  encoder.blocks.1.mlp.0.weight\n",
            "encoder.blocks.1.mlp.0.weight 2 (2048, 512)\n",
            "model.encoder.layers.1.fc1.bias  ->  encoder.blocks.1.mlp.0.bias\n",
            "encoder.blocks.1.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.fc2.weight  ->  encoder.blocks.1.mlp.2.weight\n",
            "encoder.blocks.1.mlp.2.weight 2 (512, 2048)\n",
            "model.encoder.layers.1.fc2.bias  ->  encoder.blocks.1.mlp.2.bias\n",
            "encoder.blocks.1.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.final_layer_norm.weight  ->  encoder.blocks.1.mlp_ln.weight\n",
            "encoder.blocks.1.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.final_layer_norm.bias  ->  encoder.blocks.1.mlp_ln.bias\n",
            "encoder.blocks.1.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.self_attn.k_proj.weight  ->  encoder.blocks.2.attn.key.weight\n",
            "encoder.blocks.2.attn.key.weight 2 (512, 512)\n",
            "model.encoder.layers.2.self_attn.v_proj.weight  ->  encoder.blocks.2.attn.value.weight\n",
            "encoder.blocks.2.attn.value.weight 2 (512, 512)\n",
            "model.encoder.layers.2.self_attn.v_proj.bias  ->  encoder.blocks.2.attn.value.bias\n",
            "encoder.blocks.2.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.self_attn.q_proj.weight  ->  encoder.blocks.2.attn.query.weight\n",
            "encoder.blocks.2.attn.query.weight 2 (512, 512)\n",
            "model.encoder.layers.2.self_attn.q_proj.bias  ->  encoder.blocks.2.attn.query.bias\n",
            "encoder.blocks.2.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.self_attn.out_proj.weight  ->  encoder.blocks.2.attn.out.weight\n",
            "encoder.blocks.2.attn.out.weight 2 (512, 512)\n",
            "model.encoder.layers.2.self_attn.out_proj.bias  ->  encoder.blocks.2.attn.out.bias\n",
            "encoder.blocks.2.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.self_attn_layer_norm.weight  ->  encoder.blocks.2.attn_ln.weight\n",
            "encoder.blocks.2.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.self_attn_layer_norm.bias  ->  encoder.blocks.2.attn_ln.bias\n",
            "encoder.blocks.2.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.fc1.weight  ->  encoder.blocks.2.mlp.0.weight\n",
            "encoder.blocks.2.mlp.0.weight 2 (2048, 512)\n",
            "model.encoder.layers.2.fc1.bias  ->  encoder.blocks.2.mlp.0.bias\n",
            "encoder.blocks.2.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.fc2.weight  ->  encoder.blocks.2.mlp.2.weight\n",
            "encoder.blocks.2.mlp.2.weight 2 (512, 2048)\n",
            "model.encoder.layers.2.fc2.bias  ->  encoder.blocks.2.mlp.2.bias\n",
            "encoder.blocks.2.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.final_layer_norm.weight  ->  encoder.blocks.2.mlp_ln.weight\n",
            "encoder.blocks.2.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.final_layer_norm.bias  ->  encoder.blocks.2.mlp_ln.bias\n",
            "encoder.blocks.2.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.self_attn.k_proj.weight  ->  encoder.blocks.3.attn.key.weight\n",
            "encoder.blocks.3.attn.key.weight 2 (512, 512)\n",
            "model.encoder.layers.3.self_attn.v_proj.weight  ->  encoder.blocks.3.attn.value.weight\n",
            "encoder.blocks.3.attn.value.weight 2 (512, 512)\n",
            "model.encoder.layers.3.self_attn.v_proj.bias  ->  encoder.blocks.3.attn.value.bias\n",
            "encoder.blocks.3.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.self_attn.q_proj.weight  ->  encoder.blocks.3.attn.query.weight\n",
            "encoder.blocks.3.attn.query.weight 2 (512, 512)\n",
            "model.encoder.layers.3.self_attn.q_proj.bias  ->  encoder.blocks.3.attn.query.bias\n",
            "encoder.blocks.3.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.self_attn.out_proj.weight  ->  encoder.blocks.3.attn.out.weight\n",
            "encoder.blocks.3.attn.out.weight 2 (512, 512)\n",
            "model.encoder.layers.3.self_attn.out_proj.bias  ->  encoder.blocks.3.attn.out.bias\n",
            "encoder.blocks.3.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.self_attn_layer_norm.weight  ->  encoder.blocks.3.attn_ln.weight\n",
            "encoder.blocks.3.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.self_attn_layer_norm.bias  ->  encoder.blocks.3.attn_ln.bias\n",
            "encoder.blocks.3.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.fc1.weight  ->  encoder.blocks.3.mlp.0.weight\n",
            "encoder.blocks.3.mlp.0.weight 2 (2048, 512)\n",
            "model.encoder.layers.3.fc1.bias  ->  encoder.blocks.3.mlp.0.bias\n",
            "encoder.blocks.3.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.fc2.weight  ->  encoder.blocks.3.mlp.2.weight\n",
            "encoder.blocks.3.mlp.2.weight 2 (512, 2048)\n",
            "model.encoder.layers.3.fc2.bias  ->  encoder.blocks.3.mlp.2.bias\n",
            "encoder.blocks.3.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.final_layer_norm.weight  ->  encoder.blocks.3.mlp_ln.weight\n",
            "encoder.blocks.3.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.final_layer_norm.bias  ->  encoder.blocks.3.mlp_ln.bias\n",
            "encoder.blocks.3.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.self_attn.k_proj.weight  ->  encoder.blocks.4.attn.key.weight\n",
            "encoder.blocks.4.attn.key.weight 2 (512, 512)\n",
            "model.encoder.layers.4.self_attn.v_proj.weight  ->  encoder.blocks.4.attn.value.weight\n",
            "encoder.blocks.4.attn.value.weight 2 (512, 512)\n",
            "model.encoder.layers.4.self_attn.v_proj.bias  ->  encoder.blocks.4.attn.value.bias\n",
            "encoder.blocks.4.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.self_attn.q_proj.weight  ->  encoder.blocks.4.attn.query.weight\n",
            "encoder.blocks.4.attn.query.weight 2 (512, 512)\n",
            "model.encoder.layers.4.self_attn.q_proj.bias  ->  encoder.blocks.4.attn.query.bias\n",
            "encoder.blocks.4.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.self_attn.out_proj.weight  ->  encoder.blocks.4.attn.out.weight\n",
            "encoder.blocks.4.attn.out.weight 2 (512, 512)\n",
            "model.encoder.layers.4.self_attn.out_proj.bias  ->  encoder.blocks.4.attn.out.bias\n",
            "encoder.blocks.4.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.self_attn_layer_norm.weight  ->  encoder.blocks.4.attn_ln.weight\n",
            "encoder.blocks.4.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.self_attn_layer_norm.bias  ->  encoder.blocks.4.attn_ln.bias\n",
            "encoder.blocks.4.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.fc1.weight  ->  encoder.blocks.4.mlp.0.weight\n",
            "encoder.blocks.4.mlp.0.weight 2 (2048, 512)\n",
            "model.encoder.layers.4.fc1.bias  ->  encoder.blocks.4.mlp.0.bias\n",
            "encoder.blocks.4.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.fc2.weight  ->  encoder.blocks.4.mlp.2.weight\n",
            "encoder.blocks.4.mlp.2.weight 2 (512, 2048)\n",
            "model.encoder.layers.4.fc2.bias  ->  encoder.blocks.4.mlp.2.bias\n",
            "encoder.blocks.4.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.final_layer_norm.weight  ->  encoder.blocks.4.mlp_ln.weight\n",
            "encoder.blocks.4.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.final_layer_norm.bias  ->  encoder.blocks.4.mlp_ln.bias\n",
            "encoder.blocks.4.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.self_attn.k_proj.weight  ->  encoder.blocks.5.attn.key.weight\n",
            "encoder.blocks.5.attn.key.weight 2 (512, 512)\n",
            "model.encoder.layers.5.self_attn.v_proj.weight  ->  encoder.blocks.5.attn.value.weight\n",
            "encoder.blocks.5.attn.value.weight 2 (512, 512)\n",
            "model.encoder.layers.5.self_attn.v_proj.bias  ->  encoder.blocks.5.attn.value.bias\n",
            "encoder.blocks.5.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.self_attn.q_proj.weight  ->  encoder.blocks.5.attn.query.weight\n",
            "encoder.blocks.5.attn.query.weight 2 (512, 512)\n",
            "model.encoder.layers.5.self_attn.q_proj.bias  ->  encoder.blocks.5.attn.query.bias\n",
            "encoder.blocks.5.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.self_attn.out_proj.weight  ->  encoder.blocks.5.attn.out.weight\n",
            "encoder.blocks.5.attn.out.weight 2 (512, 512)\n",
            "model.encoder.layers.5.self_attn.out_proj.bias  ->  encoder.blocks.5.attn.out.bias\n",
            "encoder.blocks.5.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.self_attn_layer_norm.weight  ->  encoder.blocks.5.attn_ln.weight\n",
            "encoder.blocks.5.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.self_attn_layer_norm.bias  ->  encoder.blocks.5.attn_ln.bias\n",
            "encoder.blocks.5.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.fc1.weight  ->  encoder.blocks.5.mlp.0.weight\n",
            "encoder.blocks.5.mlp.0.weight 2 (2048, 512)\n",
            "model.encoder.layers.5.fc1.bias  ->  encoder.blocks.5.mlp.0.bias\n",
            "encoder.blocks.5.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.fc2.weight  ->  encoder.blocks.5.mlp.2.weight\n",
            "encoder.blocks.5.mlp.2.weight 2 (512, 2048)\n",
            "model.encoder.layers.5.fc2.bias  ->  encoder.blocks.5.mlp.2.bias\n",
            "encoder.blocks.5.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.final_layer_norm.weight  ->  encoder.blocks.5.mlp_ln.weight\n",
            "encoder.blocks.5.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.final_layer_norm.bias  ->  encoder.blocks.5.mlp_ln.bias\n",
            "encoder.blocks.5.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layer_norm.weight  ->  encoder.ln_post.weight\n",
            "encoder.ln_post.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layer_norm.bias  ->  encoder.ln_post.bias\n",
            "encoder.ln_post.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.embed_tokens.weight  ->  decoder.token_embedding.weight\n",
            "decoder.token_embedding.weight 2 (51865, 512)\n",
            "model.decoder.embed_positions.weight  ->  decoder.positional_embedding\n",
            "decoder.positional_embedding 2 (448, 512)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.self_attn.k_proj.weight  ->  decoder.blocks.0.attn.key.weight\n",
            "decoder.blocks.0.attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.0.self_attn.v_proj.weight  ->  decoder.blocks.0.attn.value.weight\n",
            "decoder.blocks.0.attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.0.self_attn.v_proj.bias  ->  decoder.blocks.0.attn.value.bias\n",
            "decoder.blocks.0.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.self_attn.q_proj.weight  ->  decoder.blocks.0.attn.query.weight\n",
            "decoder.blocks.0.attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.0.self_attn.q_proj.bias  ->  decoder.blocks.0.attn.query.bias\n",
            "decoder.blocks.0.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.self_attn.out_proj.weight  ->  decoder.blocks.0.attn.out.weight\n",
            "decoder.blocks.0.attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.0.self_attn.out_proj.bias  ->  decoder.blocks.0.attn.out.bias\n",
            "decoder.blocks.0.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.self_attn_layer_norm.weight  ->  decoder.blocks.0.attn_ln.weight\n",
            "decoder.blocks.0.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.self_attn_layer_norm.bias  ->  decoder.blocks.0.attn_ln.bias\n",
            "decoder.blocks.0.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.encoder_attn.k_proj.weight  ->  decoder.blocks.0.cross_attn.key.weight\n",
            "decoder.blocks.0.cross_attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.0.encoder_attn.v_proj.weight  ->  decoder.blocks.0.cross_attn.value.weight\n",
            "decoder.blocks.0.cross_attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.0.encoder_attn.v_proj.bias  ->  decoder.blocks.0.cross_attn.value.bias\n",
            "decoder.blocks.0.cross_attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.encoder_attn.q_proj.weight  ->  decoder.blocks.0.cross_attn.query.weight\n",
            "decoder.blocks.0.cross_attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.0.encoder_attn.q_proj.bias  ->  decoder.blocks.0.cross_attn.query.bias\n",
            "decoder.blocks.0.cross_attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.encoder_attn.out_proj.weight  ->  decoder.blocks.0.cross_attn.out.weight\n",
            "decoder.blocks.0.cross_attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.0.encoder_attn.out_proj.bias  ->  decoder.blocks.0.cross_attn.out.bias\n",
            "decoder.blocks.0.cross_attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.weight  ->  decoder.blocks.0.cross_attn_ln.weight\n",
            "decoder.blocks.0.cross_attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.bias  ->  decoder.blocks.0.cross_attn_ln.bias\n",
            "decoder.blocks.0.cross_attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.fc1.weight  ->  decoder.blocks.0.mlp.0.weight\n",
            "decoder.blocks.0.mlp.0.weight 2 (2048, 512)\n",
            "model.decoder.layers.0.fc1.bias  ->  decoder.blocks.0.mlp.0.bias\n",
            "decoder.blocks.0.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.fc2.weight  ->  decoder.blocks.0.mlp.2.weight\n",
            "decoder.blocks.0.mlp.2.weight 2 (512, 2048)\n",
            "model.decoder.layers.0.fc2.bias  ->  decoder.blocks.0.mlp.2.bias\n",
            "decoder.blocks.0.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.final_layer_norm.weight  ->  decoder.blocks.0.mlp_ln.weight\n",
            "decoder.blocks.0.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.final_layer_norm.bias  ->  decoder.blocks.0.mlp_ln.bias\n",
            "decoder.blocks.0.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.self_attn.k_proj.weight  ->  decoder.blocks.1.attn.key.weight\n",
            "decoder.blocks.1.attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.1.self_attn.v_proj.weight  ->  decoder.blocks.1.attn.value.weight\n",
            "decoder.blocks.1.attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.1.self_attn.v_proj.bias  ->  decoder.blocks.1.attn.value.bias\n",
            "decoder.blocks.1.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.self_attn.q_proj.weight  ->  decoder.blocks.1.attn.query.weight\n",
            "decoder.blocks.1.attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.1.self_attn.q_proj.bias  ->  decoder.blocks.1.attn.query.bias\n",
            "decoder.blocks.1.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.self_attn.out_proj.weight  ->  decoder.blocks.1.attn.out.weight\n",
            "decoder.blocks.1.attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.1.self_attn.out_proj.bias  ->  decoder.blocks.1.attn.out.bias\n",
            "decoder.blocks.1.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.self_attn_layer_norm.weight  ->  decoder.blocks.1.attn_ln.weight\n",
            "decoder.blocks.1.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.self_attn_layer_norm.bias  ->  decoder.blocks.1.attn_ln.bias\n",
            "decoder.blocks.1.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.encoder_attn.k_proj.weight  ->  decoder.blocks.1.cross_attn.key.weight\n",
            "decoder.blocks.1.cross_attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.1.encoder_attn.v_proj.weight  ->  decoder.blocks.1.cross_attn.value.weight\n",
            "decoder.blocks.1.cross_attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.1.encoder_attn.v_proj.bias  ->  decoder.blocks.1.cross_attn.value.bias\n",
            "decoder.blocks.1.cross_attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.encoder_attn.q_proj.weight  ->  decoder.blocks.1.cross_attn.query.weight\n",
            "decoder.blocks.1.cross_attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.1.encoder_attn.q_proj.bias  ->  decoder.blocks.1.cross_attn.query.bias\n",
            "decoder.blocks.1.cross_attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.encoder_attn.out_proj.weight  ->  decoder.blocks.1.cross_attn.out.weight\n",
            "decoder.blocks.1.cross_attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.1.encoder_attn.out_proj.bias  ->  decoder.blocks.1.cross_attn.out.bias\n",
            "decoder.blocks.1.cross_attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.weight  ->  decoder.blocks.1.cross_attn_ln.weight\n",
            "decoder.blocks.1.cross_attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.bias  ->  decoder.blocks.1.cross_attn_ln.bias\n",
            "decoder.blocks.1.cross_attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.fc1.weight  ->  decoder.blocks.1.mlp.0.weight\n",
            "decoder.blocks.1.mlp.0.weight 2 (2048, 512)\n",
            "model.decoder.layers.1.fc1.bias  ->  decoder.blocks.1.mlp.0.bias\n",
            "decoder.blocks.1.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.fc2.weight  ->  decoder.blocks.1.mlp.2.weight\n",
            "decoder.blocks.1.mlp.2.weight 2 (512, 2048)\n",
            "model.decoder.layers.1.fc2.bias  ->  decoder.blocks.1.mlp.2.bias\n",
            "decoder.blocks.1.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.final_layer_norm.weight  ->  decoder.blocks.1.mlp_ln.weight\n",
            "decoder.blocks.1.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.final_layer_norm.bias  ->  decoder.blocks.1.mlp_ln.bias\n",
            "decoder.blocks.1.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.self_attn.k_proj.weight  ->  decoder.blocks.2.attn.key.weight\n",
            "decoder.blocks.2.attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.2.self_attn.v_proj.weight  ->  decoder.blocks.2.attn.value.weight\n",
            "decoder.blocks.2.attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.2.self_attn.v_proj.bias  ->  decoder.blocks.2.attn.value.bias\n",
            "decoder.blocks.2.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.self_attn.q_proj.weight  ->  decoder.blocks.2.attn.query.weight\n",
            "decoder.blocks.2.attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.2.self_attn.q_proj.bias  ->  decoder.blocks.2.attn.query.bias\n",
            "decoder.blocks.2.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.self_attn.out_proj.weight  ->  decoder.blocks.2.attn.out.weight\n",
            "decoder.blocks.2.attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.2.self_attn.out_proj.bias  ->  decoder.blocks.2.attn.out.bias\n",
            "decoder.blocks.2.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.self_attn_layer_norm.weight  ->  decoder.blocks.2.attn_ln.weight\n",
            "decoder.blocks.2.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.self_attn_layer_norm.bias  ->  decoder.blocks.2.attn_ln.bias\n",
            "decoder.blocks.2.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.encoder_attn.k_proj.weight  ->  decoder.blocks.2.cross_attn.key.weight\n",
            "decoder.blocks.2.cross_attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.2.encoder_attn.v_proj.weight  ->  decoder.blocks.2.cross_attn.value.weight\n",
            "decoder.blocks.2.cross_attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.2.encoder_attn.v_proj.bias  ->  decoder.blocks.2.cross_attn.value.bias\n",
            "decoder.blocks.2.cross_attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.encoder_attn.q_proj.weight  ->  decoder.blocks.2.cross_attn.query.weight\n",
            "decoder.blocks.2.cross_attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.2.encoder_attn.q_proj.bias  ->  decoder.blocks.2.cross_attn.query.bias\n",
            "decoder.blocks.2.cross_attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.encoder_attn.out_proj.weight  ->  decoder.blocks.2.cross_attn.out.weight\n",
            "decoder.blocks.2.cross_attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.2.encoder_attn.out_proj.bias  ->  decoder.blocks.2.cross_attn.out.bias\n",
            "decoder.blocks.2.cross_attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.weight  ->  decoder.blocks.2.cross_attn_ln.weight\n",
            "decoder.blocks.2.cross_attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.bias  ->  decoder.blocks.2.cross_attn_ln.bias\n",
            "decoder.blocks.2.cross_attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.fc1.weight  ->  decoder.blocks.2.mlp.0.weight\n",
            "decoder.blocks.2.mlp.0.weight 2 (2048, 512)\n",
            "model.decoder.layers.2.fc1.bias  ->  decoder.blocks.2.mlp.0.bias\n",
            "decoder.blocks.2.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.fc2.weight  ->  decoder.blocks.2.mlp.2.weight\n",
            "decoder.blocks.2.mlp.2.weight 2 (512, 2048)\n",
            "model.decoder.layers.2.fc2.bias  ->  decoder.blocks.2.mlp.2.bias\n",
            "decoder.blocks.2.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.final_layer_norm.weight  ->  decoder.blocks.2.mlp_ln.weight\n",
            "decoder.blocks.2.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.final_layer_norm.bias  ->  decoder.blocks.2.mlp_ln.bias\n",
            "decoder.blocks.2.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.self_attn.k_proj.weight  ->  decoder.blocks.3.attn.key.weight\n",
            "decoder.blocks.3.attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.3.self_attn.v_proj.weight  ->  decoder.blocks.3.attn.value.weight\n",
            "decoder.blocks.3.attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.3.self_attn.v_proj.bias  ->  decoder.blocks.3.attn.value.bias\n",
            "decoder.blocks.3.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.self_attn.q_proj.weight  ->  decoder.blocks.3.attn.query.weight\n",
            "decoder.blocks.3.attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.3.self_attn.q_proj.bias  ->  decoder.blocks.3.attn.query.bias\n",
            "decoder.blocks.3.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.self_attn.out_proj.weight  ->  decoder.blocks.3.attn.out.weight\n",
            "decoder.blocks.3.attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.3.self_attn.out_proj.bias  ->  decoder.blocks.3.attn.out.bias\n",
            "decoder.blocks.3.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.self_attn_layer_norm.weight  ->  decoder.blocks.3.attn_ln.weight\n",
            "decoder.blocks.3.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.self_attn_layer_norm.bias  ->  decoder.blocks.3.attn_ln.bias\n",
            "decoder.blocks.3.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.encoder_attn.k_proj.weight  ->  decoder.blocks.3.cross_attn.key.weight\n",
            "decoder.blocks.3.cross_attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.3.encoder_attn.v_proj.weight  ->  decoder.blocks.3.cross_attn.value.weight\n",
            "decoder.blocks.3.cross_attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.3.encoder_attn.v_proj.bias  ->  decoder.blocks.3.cross_attn.value.bias\n",
            "decoder.blocks.3.cross_attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.encoder_attn.q_proj.weight  ->  decoder.blocks.3.cross_attn.query.weight\n",
            "decoder.blocks.3.cross_attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.3.encoder_attn.q_proj.bias  ->  decoder.blocks.3.cross_attn.query.bias\n",
            "decoder.blocks.3.cross_attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.encoder_attn.out_proj.weight  ->  decoder.blocks.3.cross_attn.out.weight\n",
            "decoder.blocks.3.cross_attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.3.encoder_attn.out_proj.bias  ->  decoder.blocks.3.cross_attn.out.bias\n",
            "decoder.blocks.3.cross_attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.weight  ->  decoder.blocks.3.cross_attn_ln.weight\n",
            "decoder.blocks.3.cross_attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.bias  ->  decoder.blocks.3.cross_attn_ln.bias\n",
            "decoder.blocks.3.cross_attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.fc1.weight  ->  decoder.blocks.3.mlp.0.weight\n",
            "decoder.blocks.3.mlp.0.weight 2 (2048, 512)\n",
            "model.decoder.layers.3.fc1.bias  ->  decoder.blocks.3.mlp.0.bias\n",
            "decoder.blocks.3.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.fc2.weight  ->  decoder.blocks.3.mlp.2.weight\n",
            "decoder.blocks.3.mlp.2.weight 2 (512, 2048)\n",
            "model.decoder.layers.3.fc2.bias  ->  decoder.blocks.3.mlp.2.bias\n",
            "decoder.blocks.3.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.final_layer_norm.weight  ->  decoder.blocks.3.mlp_ln.weight\n",
            "decoder.blocks.3.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.final_layer_norm.bias  ->  decoder.blocks.3.mlp_ln.bias\n",
            "decoder.blocks.3.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.self_attn.k_proj.weight  ->  decoder.blocks.4.attn.key.weight\n",
            "decoder.blocks.4.attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.4.self_attn.v_proj.weight  ->  decoder.blocks.4.attn.value.weight\n",
            "decoder.blocks.4.attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.4.self_attn.v_proj.bias  ->  decoder.blocks.4.attn.value.bias\n",
            "decoder.blocks.4.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.self_attn.q_proj.weight  ->  decoder.blocks.4.attn.query.weight\n",
            "decoder.blocks.4.attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.4.self_attn.q_proj.bias  ->  decoder.blocks.4.attn.query.bias\n",
            "decoder.blocks.4.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.self_attn.out_proj.weight  ->  decoder.blocks.4.attn.out.weight\n",
            "decoder.blocks.4.attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.4.self_attn.out_proj.bias  ->  decoder.blocks.4.attn.out.bias\n",
            "decoder.blocks.4.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.self_attn_layer_norm.weight  ->  decoder.blocks.4.attn_ln.weight\n",
            "decoder.blocks.4.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.self_attn_layer_norm.bias  ->  decoder.blocks.4.attn_ln.bias\n",
            "decoder.blocks.4.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.encoder_attn.k_proj.weight  ->  decoder.blocks.4.cross_attn.key.weight\n",
            "decoder.blocks.4.cross_attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.4.encoder_attn.v_proj.weight  ->  decoder.blocks.4.cross_attn.value.weight\n",
            "decoder.blocks.4.cross_attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.4.encoder_attn.v_proj.bias  ->  decoder.blocks.4.cross_attn.value.bias\n",
            "decoder.blocks.4.cross_attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.encoder_attn.q_proj.weight  ->  decoder.blocks.4.cross_attn.query.weight\n",
            "decoder.blocks.4.cross_attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.4.encoder_attn.q_proj.bias  ->  decoder.blocks.4.cross_attn.query.bias\n",
            "decoder.blocks.4.cross_attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.encoder_attn.out_proj.weight  ->  decoder.blocks.4.cross_attn.out.weight\n",
            "decoder.blocks.4.cross_attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.4.encoder_attn.out_proj.bias  ->  decoder.blocks.4.cross_attn.out.bias\n",
            "decoder.blocks.4.cross_attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.weight  ->  decoder.blocks.4.cross_attn_ln.weight\n",
            "decoder.blocks.4.cross_attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.bias  ->  decoder.blocks.4.cross_attn_ln.bias\n",
            "decoder.blocks.4.cross_attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.fc1.weight  ->  decoder.blocks.4.mlp.0.weight\n",
            "decoder.blocks.4.mlp.0.weight 2 (2048, 512)\n",
            "model.decoder.layers.4.fc1.bias  ->  decoder.blocks.4.mlp.0.bias\n",
            "decoder.blocks.4.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.fc2.weight  ->  decoder.blocks.4.mlp.2.weight\n",
            "decoder.blocks.4.mlp.2.weight 2 (512, 2048)\n",
            "model.decoder.layers.4.fc2.bias  ->  decoder.blocks.4.mlp.2.bias\n",
            "decoder.blocks.4.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.final_layer_norm.weight  ->  decoder.blocks.4.mlp_ln.weight\n",
            "decoder.blocks.4.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.final_layer_norm.bias  ->  decoder.blocks.4.mlp_ln.bias\n",
            "decoder.blocks.4.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.self_attn.k_proj.weight  ->  decoder.blocks.5.attn.key.weight\n",
            "decoder.blocks.5.attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.5.self_attn.v_proj.weight  ->  decoder.blocks.5.attn.value.weight\n",
            "decoder.blocks.5.attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.5.self_attn.v_proj.bias  ->  decoder.blocks.5.attn.value.bias\n",
            "decoder.blocks.5.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.self_attn.q_proj.weight  ->  decoder.blocks.5.attn.query.weight\n",
            "decoder.blocks.5.attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.5.self_attn.q_proj.bias  ->  decoder.blocks.5.attn.query.bias\n",
            "decoder.blocks.5.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.self_attn.out_proj.weight  ->  decoder.blocks.5.attn.out.weight\n",
            "decoder.blocks.5.attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.5.self_attn.out_proj.bias  ->  decoder.blocks.5.attn.out.bias\n",
            "decoder.blocks.5.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.self_attn_layer_norm.weight  ->  decoder.blocks.5.attn_ln.weight\n",
            "decoder.blocks.5.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.self_attn_layer_norm.bias  ->  decoder.blocks.5.attn_ln.bias\n",
            "decoder.blocks.5.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.encoder_attn.k_proj.weight  ->  decoder.blocks.5.cross_attn.key.weight\n",
            "decoder.blocks.5.cross_attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.5.encoder_attn.v_proj.weight  ->  decoder.blocks.5.cross_attn.value.weight\n",
            "decoder.blocks.5.cross_attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.5.encoder_attn.v_proj.bias  ->  decoder.blocks.5.cross_attn.value.bias\n",
            "decoder.blocks.5.cross_attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.encoder_attn.q_proj.weight  ->  decoder.blocks.5.cross_attn.query.weight\n",
            "decoder.blocks.5.cross_attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.5.encoder_attn.q_proj.bias  ->  decoder.blocks.5.cross_attn.query.bias\n",
            "decoder.blocks.5.cross_attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.encoder_attn.out_proj.weight  ->  decoder.blocks.5.cross_attn.out.weight\n",
            "decoder.blocks.5.cross_attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.5.encoder_attn.out_proj.bias  ->  decoder.blocks.5.cross_attn.out.bias\n",
            "decoder.blocks.5.cross_attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.weight  ->  decoder.blocks.5.cross_attn_ln.weight\n",
            "decoder.blocks.5.cross_attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.bias  ->  decoder.blocks.5.cross_attn_ln.bias\n",
            "decoder.blocks.5.cross_attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.fc1.weight  ->  decoder.blocks.5.mlp.0.weight\n",
            "decoder.blocks.5.mlp.0.weight 2 (2048, 512)\n",
            "model.decoder.layers.5.fc1.bias  ->  decoder.blocks.5.mlp.0.bias\n",
            "decoder.blocks.5.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.fc2.weight  ->  decoder.blocks.5.mlp.2.weight\n",
            "decoder.blocks.5.mlp.2.weight 2 (512, 2048)\n",
            "model.decoder.layers.5.fc2.bias  ->  decoder.blocks.5.mlp.2.bias\n",
            "decoder.blocks.5.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.final_layer_norm.weight  ->  decoder.blocks.5.mlp_ln.weight\n",
            "decoder.blocks.5.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.final_layer_norm.bias  ->  decoder.blocks.5.mlp_ln.bias\n",
            "decoder.blocks.5.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layer_norm.weight  ->  decoder.ln.weight\n",
            "decoder.ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layer_norm.bias  ->  decoder.ln.bias\n",
            "decoder.ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "Skipping proj_out.weight\n",
            "Done. Output file:  ggml/ggml-model.bin\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir ./ggml\n",
        "!python whisper.cpp/models/convert-h5-to-ggml.py ./final-model ./whisper-github ./ggml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOdPpP1fMRr7"
      },
      "source": [
        "For smaller size and better performance, we can also [quantize the GGML model](https://github.com/ggerganov/whisper.cpp/discussions/838):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD4AX-4ZL8xN",
        "outputId": "196ac1cb-f55b-4513-8014-dcfbabd73c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- Including CPU backend\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP: TRUE (found version \"4.5\")\n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- Configuring done (1.9s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/whisper.cpp/build\n",
            "[  2%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\u001b[0m\n",
            "[ 17%] \u001b[32m\u001b[1mLinking CXX shared library libggml-base.so\u001b[0m\n",
            "[ 17%] Built target ggml-base\n",
            "[ 20%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32m\u001b[1mLinking CXX shared library libggml-cpu.so\u001b[0m\n",
            "[ 40%] Built target ggml-cpu\n",
            "[ 42%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32m\u001b[1mLinking CXX shared library libggml.so\u001b[0m\n",
            "[ 45%] Built target ggml\n",
            "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/whisper.dir/whisper.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared library libwhisper.so\u001b[0m\n",
            "[ 50%] Built target whisper\n",
            "[ 52%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/common.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/common-ggml.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/grammar-parser.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32m\u001b[1mLinking CXX static library libcommon.a\u001b[0m\n",
            "[ 60%] Built target common\n",
            "[ 62%] \u001b[32mBuilding CXX object examples/cli/CMakeFiles/whisper-cli.dir/cli.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/whisper-cli\u001b[0m\n",
            "[ 65%] Built target whisper-cli\n",
            "[ 67%] \u001b[32mBuilding CXX object examples/bench/CMakeFiles/whisper-bench.dir/bench.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/whisper-bench\u001b[0m\n",
            "[ 70%] Built target whisper-bench\n",
            "[ 72%] \u001b[32mBuilding CXX object examples/server/CMakeFiles/whisper-server.dir/server.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/whisper-server\u001b[0m\n",
            "[ 75%] Built target whisper-server\n",
            "[ 77%] \u001b[32mBuilding CXX object examples/quantize/CMakeFiles/quantize.dir/quantize.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/quantize\u001b[0m\n",
            "[ 80%] Built target quantize\n",
            "[ 82%] \u001b[32mBuilding CXX object examples/deprecation-warning/CMakeFiles/main.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/main\u001b[0m\n",
            "[ 85%] Built target main\n",
            "[ 87%] \u001b[32mBuilding CXX object examples/deprecation-warning/CMakeFiles/bench.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/bench\u001b[0m\n",
            "[ 90%] Built target bench\n",
            "[ 92%] \u001b[32mBuilding CXX object examples/deprecation-warning/CMakeFiles/stream.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/stream\u001b[0m\n",
            "[ 95%] Built target stream\n",
            "[ 97%] \u001b[32mBuilding CXX object examples/deprecation-warning/CMakeFiles/command.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/command\u001b[0m\n",
            "[100%] Built target command\n",
            "whisper_model_quantize: loading model from './ggml/ggml-model.bin'\n",
            "whisper_model_quantize: n_vocab       = 51865\n",
            "whisper_model_quantize: n_audio_ctx   = 1500\n",
            "whisper_model_quantize: n_audio_state = 512\n",
            "whisper_model_quantize: n_audio_head  = 8\n",
            "whisper_model_quantize: n_audio_layer = 6\n",
            "whisper_model_quantize: n_text_ctx    = 448\n",
            "whisper_model_quantize: n_text_state  = 512\n",
            "whisper_model_quantize: n_text_head   = 8\n",
            "whisper_model_quantize: n_text_layer  = 6\n",
            "whisper_model_quantize: n_mels        = 80\n",
            "whisper_model_quantize: ftype (src)   = 1\n",
            "whisper_model_quantize: qntvr (src)   = 0\n",
            "whisper_model_quantize: ftype (dst)   = 2007\n",
            "whisper_model_quantize: qntvr (dst)   = 2\n",
            "                                            encoder.conv1.weight - [    3,    80,   512], type =    f16 size =    0.234 MB\n",
            "                                              encoder.conv1.bias - [    1,   512,     1], type =    f32 size =    0.002 MB\n",
            "                                            encoder.conv2.weight - [    3,   512,   512], type =    f16 size =    1.500 MB\n",
            "                                              encoder.conv2.bias - [    1,   512,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.positional_embedding - [  512,  1500,     1], type =    f32 size =    2.930 MB\n",
            "                                encoder.blocks.0.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              encoder.blocks.0.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.0.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.0.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.0.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.0.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  encoder.blocks.0.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.0.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.0.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.0.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.0.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.0.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.0.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.0.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.0.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.1.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              encoder.blocks.1.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.1.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.1.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.1.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.1.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  encoder.blocks.1.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.1.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.1.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.1.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.1.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.1.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.1.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.1.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.1.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.2.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              encoder.blocks.2.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.2.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.2.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.2.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.2.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  encoder.blocks.2.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.2.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.2.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.2.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.2.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.2.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.2.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.2.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.2.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.3.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              encoder.blocks.3.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.3.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.3.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.3.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.3.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  encoder.blocks.3.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.3.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.3.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.3.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.3.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.3.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.3.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.3.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.3.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.4.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              encoder.blocks.4.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.4.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.4.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.4.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.4.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  encoder.blocks.4.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.4.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.4.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.4.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.4.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.4.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.4.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.4.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.4.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.5.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              encoder.blocks.5.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.5.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.5.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.5.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.5.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  encoder.blocks.5.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.5.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.5.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.5.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.5.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.5.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.5.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.5.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.5.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                          encoder.ln_post.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                            encoder.ln_post.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.token_embedding.weight - [  512, 51865,     1], type =    f16 size =   101.30 MB ->    26.91 MB\n",
            "                                    decoder.positional_embedding - [  512,   448,     1], type =    f32 size =    0.875 MB\n",
            "                                decoder.blocks.0.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              decoder.blocks.0.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.0.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.0.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.0.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.0.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  decoder.blocks.0.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.0.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.0.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.0.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                        decoder.blocks.0.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.0.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.0.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.0.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.0.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                            decoder.blocks.0.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.0.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.0.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.0.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.0.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.0.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.0.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.0.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.0.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.1.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              decoder.blocks.1.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.1.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.1.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.1.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.1.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  decoder.blocks.1.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.1.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.1.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.1.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                        decoder.blocks.1.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.1.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.1.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.1.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.1.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                            decoder.blocks.1.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.1.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.1.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.1.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.1.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.1.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.1.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.1.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.1.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.2.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              decoder.blocks.2.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.2.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.2.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.2.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.2.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  decoder.blocks.2.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.2.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.2.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.2.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                        decoder.blocks.2.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.2.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.2.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.2.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.2.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                            decoder.blocks.2.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.2.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.2.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.2.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.2.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.2.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.2.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.2.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.2.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.3.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              decoder.blocks.3.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.3.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.3.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.3.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.3.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  decoder.blocks.3.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.3.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.3.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.3.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                        decoder.blocks.3.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.3.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.3.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.3.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.3.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                            decoder.blocks.3.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.3.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.3.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.3.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.3.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.3.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.3.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.3.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.3.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.4.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              decoder.blocks.4.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.4.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.4.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.4.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.4.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  decoder.blocks.4.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.4.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.4.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.4.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                        decoder.blocks.4.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.4.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.4.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.4.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.4.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                            decoder.blocks.4.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.4.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.4.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.4.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.4.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.4.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.4.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.4.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.4.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.5.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              decoder.blocks.5.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.5.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.5.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.5.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.5.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  decoder.blocks.5.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.5.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.5.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.5.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                        decoder.blocks.5.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.5.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.5.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.5.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.5.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                            decoder.blocks.5.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.5.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.5.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.5.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.5.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.5.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.5.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.5.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.5.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                               decoder.ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                                 decoder.ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "ggml_common_quantize_0: model size  =   276.92 MB\n",
            "ggml_common_quantize_0: quant size  =    77.42 MB | ftype = 7 (q8_0)\n",
            "\n",
            "main: quantize time =   953.94 ms\n",
            "main:    total time =   953.94 ms\n",
            "whisper_model_quantize: loading model from './ggml/ggml-model.bin'\n",
            "whisper_model_quantize: n_vocab       = 51865\n",
            "whisper_model_quantize: n_audio_ctx   = 1500\n",
            "whisper_model_quantize: n_audio_state = 512\n",
            "whisper_model_quantize: n_audio_head  = 8\n",
            "whisper_model_quantize: n_audio_layer = 6\n",
            "whisper_model_quantize: n_text_ctx    = 448\n",
            "whisper_model_quantize: n_text_state  = 512\n",
            "whisper_model_quantize: n_text_head   = 8\n",
            "whisper_model_quantize: n_text_layer  = 6\n",
            "whisper_model_quantize: n_mels        = 80\n",
            "whisper_model_quantize: ftype (src)   = 1\n",
            "whisper_model_quantize: qntvr (src)   = 0\n",
            "whisper_model_quantize: ftype (dst)   = 2008\n",
            "whisper_model_quantize: qntvr (dst)   = 2\n",
            "                                            encoder.conv1.weight - [    3,    80,   512], type =    f16 size =    0.234 MB\n",
            "                                              encoder.conv1.bias - [    1,   512,     1], type =    f32 size =    0.002 MB\n",
            "                                            encoder.conv2.weight - [    3,   512,   512], type =    f16 size =    1.500 MB\n",
            "                                              encoder.conv2.bias - [    1,   512,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.positional_embedding - [  512,  1500,     1], type =    f32 size =    2.930 MB\n",
            "                                encoder.blocks.0.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              encoder.blocks.0.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.0.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.0.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.0.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.0.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  encoder.blocks.0.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.0.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.0.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.0.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.0.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.0.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.0.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.0.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.0.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.1.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              encoder.blocks.1.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.1.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.1.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.1.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.1.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  encoder.blocks.1.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.1.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.1.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.1.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.1.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.1.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.1.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.1.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.1.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.2.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              encoder.blocks.2.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.2.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.2.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.2.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.2.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  encoder.blocks.2.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.2.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.2.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.2.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.2.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.2.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.2.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.2.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.2.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.3.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              encoder.blocks.3.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.3.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.3.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.3.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.3.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  encoder.blocks.3.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.3.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.3.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.3.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.3.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.3.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.3.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.3.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.3.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.4.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              encoder.blocks.4.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.4.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.4.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.4.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.4.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  encoder.blocks.4.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.4.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.4.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.4.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.4.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.4.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.4.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.4.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.4.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.5.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              encoder.blocks.5.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.5.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.5.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.5.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.5.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  encoder.blocks.5.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.5.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.5.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.5.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.5.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.5.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.5.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.5.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.5.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                          encoder.ln_post.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                            encoder.ln_post.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.token_embedding.weight - [  512, 51865,     1], type =    f16 size =   101.30 MB ->    17.41 MB\n",
            "                                    decoder.positional_embedding - [  512,   448,     1], type =    f32 size =    0.875 MB\n",
            "                                decoder.blocks.0.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              decoder.blocks.0.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.0.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.0.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.0.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.0.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  decoder.blocks.0.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.0.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.0.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.0.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                        decoder.blocks.0.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.0.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.0.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.0.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.0.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                            decoder.blocks.0.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.0.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.0.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.0.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.0.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.0.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.0.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.0.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.0.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.1.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              decoder.blocks.1.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.1.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.1.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.1.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.1.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  decoder.blocks.1.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.1.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.1.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.1.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                        decoder.blocks.1.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.1.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.1.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.1.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.1.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                            decoder.blocks.1.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.1.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.1.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.1.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.1.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.1.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.1.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.1.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.1.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.2.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              decoder.blocks.2.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.2.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.2.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.2.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.2.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  decoder.blocks.2.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.2.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.2.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.2.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                        decoder.blocks.2.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.2.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.2.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.2.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.2.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                            decoder.blocks.2.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.2.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.2.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.2.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.2.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.2.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.2.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.2.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.2.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.3.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              decoder.blocks.3.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.3.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.3.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.3.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.3.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  decoder.blocks.3.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.3.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.3.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.3.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                        decoder.blocks.3.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.3.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.3.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.3.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.3.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                            decoder.blocks.3.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.3.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.3.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.3.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.3.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.3.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.3.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.3.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.3.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.4.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              decoder.blocks.4.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.4.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.4.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.4.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.4.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  decoder.blocks.4.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.4.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.4.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.4.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                        decoder.blocks.4.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.4.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.4.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.4.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.4.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                            decoder.blocks.4.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.4.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.4.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.4.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.4.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.4.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.4.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.4.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.4.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.5.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              decoder.blocks.5.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.5.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.5.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.5.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.5.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  decoder.blocks.5.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.5.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.5.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.5.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                        decoder.blocks.5.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.5.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.5.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.5.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.5.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                            decoder.blocks.5.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.5.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.5.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.5.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.5.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.5.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.5.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.5.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.5.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                               decoder.ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                                 decoder.ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "ggml_common_quantize_0: model size  =   276.92 MB\n",
            "ggml_common_quantize_0: quant size  =    52.18 MB | ftype = 8 (q5_0)\n",
            "\n",
            "main: quantize time =   855.31 ms\n",
            "main:    total time =   855.31 ms\n"
          ]
        }
      ],
      "source": [
        "!cd whisper.cpp && cmake -B build && cmake --build build --config Release\n",
        "!./whisper.cpp/build/bin/quantize ./ggml/ggml-model.bin ./ggml/ggml-model-q8_0.bin q8_0\n",
        "!./whisper.cpp/build/bin/quantize ./ggml/ggml-model.bin ./ggml/ggml-model-q5_0.bin q5_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNH_WV-lMW9n"
      },
      "source": [
        "Now, let's make sure that the `.ggml` model works. Start by downloading some test audio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFcwkwhXMYKt",
        "outputId": "828d9795-5d5f-4bce-a2ec-804b925a3a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-25 19:13:43--  https://www.archive.org/download/alice_au_pays_des_merveilles_1811_librivox/aliceaupays_04_carroll_128kb.mp3\n",
            "Resolving www.archive.org (www.archive.org)... 207.241.224.2\n",
            "Connecting to www.archive.org (www.archive.org)|207.241.224.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://archive.org/download/alice_au_pays_des_merveilles_1811_librivox/aliceaupays_04_carroll_128kb.mp3 [following]\n",
            "--2025-03-25 19:13:45--  https://archive.org/download/alice_au_pays_des_merveilles_1811_librivox/aliceaupays_04_carroll_128kb.mp3\n",
            "Resolving archive.org (archive.org)... 207.241.224.2\n",
            "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ia803201.us.archive.org/25/items/alice_au_pays_des_merveilles_1811_librivox/aliceaupays_04_carroll_128kb.mp3 [following]\n",
            "--2025-03-25 19:13:46--  https://ia803201.us.archive.org/25/items/alice_au_pays_des_merveilles_1811_librivox/aliceaupays_04_carroll_128kb.mp3\n",
            "Resolving ia803201.us.archive.org (ia803201.us.archive.org)... 207.241.234.121\n",
            "Connecting to ia803201.us.archive.org (ia803201.us.archive.org)|207.241.234.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20279887 (19M) [audio/mpeg]\n",
            "Saving to: ‘./test-audio/aliceaupays_04_carroll_128kb.mp3’\n",
            "\n",
            "aliceaupays_04_carr 100%[===================>]  19.34M  9.13MB/s    in 2.1s    \n",
            "\n",
            "2025-03-25 19:13:49 (9.13 MB/s) - ‘./test-audio/aliceaupays_04_carroll_128kb.mp3’ saved [20279887/20279887]\n",
            "\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mp3, from './test-audio/aliceaupays_04_carroll_128kb.mp3':\n",
            "  Metadata:\n",
            "    title           : 04 - L'Habitation du Lapin Blanc\n",
            "    artist          : Lewis Carroll\n",
            "    album           : Aventures d'Alice au Pays des Merveilles\n",
            "    genre           : speech\n",
            "    track           : 5\n",
            "  Duration: 00:21:07.20, start: 0.025057, bitrate: 128 kb/s\n",
            "  Stream #0:0: Audio: mp3, 44100 Hz, mono, fltp, 128 kb/s\n",
            "    Metadata:\n",
            "      encoder         : LAME3.99r\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to './test-audio/recording-fr-4.wav':\n",
            "  Metadata:\n",
            "    INAM            : 04 - L'Habitation du Lapin Blanc\n",
            "    IART            : Lewis Carroll\n",
            "    IPRD            : Aventures d'Alice au Pays des Merveilles\n",
            "    IGNR            : speech\n",
            "    IPRT            : 5\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=     313kB time=00:00:09.99 bitrate= 256.2kbits/s speed= 291x    \n",
            "video:0kB audio:312kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.068125%\n"
          ]
        }
      ],
      "source": [
        "!mkdir ./test-audio\n",
        "# Download the first chapter of Alice in Wonderland (in French)\n",
        "!wget -P ./test-audio/ https://www.archive.org/download/alice_au_pays_des_merveilles_1811_librivox/aliceaupays_04_carroll_128kb.mp3\n",
        "# Convert it to a format that's understandable by whisper.cpp:\n",
        "# -t 30                 Take the first 30s\n",
        "# -i ...                Input path\n",
        "# -ar 16000             Sample rate of 16000 HZ\n",
        "# -ac 1                 1 audio channel\n",
        "# -codec:a pcm_s16le    Audio codec\n",
        "!ffmpeg -t 10 -i ./test-audio/aliceaupays_04_carroll_128kb.mp3 -ar 16000 -ac 1 -codec:a pcm_s16le ./test-audio/recording-fr-4.wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg5hkQpyq1io"
      },
      "source": [
        "Next, use the `whisper-cli` command to transcribe the audio using our GGML model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur0wEF6SULr4",
        "outputId": "cfcf8dd5-b9b1-4b0d-a260-fc544f391df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Capétre 4, de aventure, d'Alic, au Pays des Marseille, par l'Ouestara. Cet enregistrement et les prévoxes fait partie.\n"
          ]
        }
      ],
      "source": [
        "# Test converting the WAV file to text using the GGML file that we built.\n",
        "# The \"-np\" argument causes only the recognised text to be printed: \n",
        "!./whisper.cpp/build/bin/whisper-cli --language fr -np --no-timestamps -m ./ggml/ggml-model.bin ./test-audio/recording-fr-4.wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW2jOvmsLsAm"
      },
      "source": [
        "## Packaging for Joplin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPGYcxa7zmO5"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperFeatureExtractor, WhisperTokenizer\n",
        "\n",
        "feature_extractor = processor.feature_extractor\n",
        "tokenizer_original = processor.tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAjHVQPCueTO"
      },
      "source": [
        "We'll create a customized tokenizer based on `tokenizer_original` in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2-3B1TW3Tc1"
      },
      "source": [
        "## Vocabulary adjustements\n",
        "\n",
        "Next, we remove several unwanted tokens from the vocabulary. This section is originally from `whisper_vocab_cleanup.ipynb`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWsP8YfrcmUC",
        "outputId": "f335d4c8-f2b3-40be-e780-165320ff13ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('whisper-default-tokenizer/tokenizer_config.json',\n",
              " 'whisper-default-tokenizer/special_tokens_map.json',\n",
              " 'whisper-default-tokenizer/vocab.json',\n",
              " 'whisper-default-tokenizer/merges.txt',\n",
              " 'whisper-default-tokenizer/normalizer.json',\n",
              " 'whisper-default-tokenizer/added_tokens.json')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1: Save the vocabulary to a file\n",
        "tokenizer_directory = Path('whisper-default-tokenizer')\n",
        "tokenizer_original.save_pretrained(tokenizer_directory)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES0enoY-ezxm"
      },
      "source": [
        "Now that the tokenizer is saved in `tokenizer_directory`, we can load `tokenizer_directory/vocab.json` and modify it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtHNBGVPewT2"
      },
      "outputs": [],
      "source": [
        "# Step 2: Get vocab.json\n",
        "import json\n",
        "\n",
        "def json_from_path(path: Path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        return json.loads(f.read())\n",
        "\n",
        "vocab = json_from_path(tokenizer_directory / 'vocab.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBqPdNpLkSYg"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "NONWORD_REGEX = re.compile(r'[ \\t?.,;!()/\\-«»]+')\n",
        "def split_by_word(text: str):\n",
        "    \"\"\" Splits the given `text` into words. Returns a list of those words. \"\"\"\n",
        "    return NONWORD_REGEX.split(text)\n",
        "\n",
        "\n",
        "# This character marks the beginning of a word in vocab.json\n",
        "word_start_char = 'Ġ'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPBQrfHmsEdz"
      },
      "outputs": [],
      "source": [
        "# Step 3: Replace!\n",
        "next_replacement_idx = 0\n",
        "new_vocab = {}\n",
        "\n",
        "# Token IDs can be found by inspecting the original vocab.json. These token IDs\n",
        "# are specific to the multilingual whisper-tiny, but may also work for whisper-base. Each remapping should be unique.\n",
        "token_id_remappings = {\n",
        "    19186: \"[swearS1]\", # s***\n",
        "    30748: word_start_char + \"[swearS2]\",\n",
        "    4611: word_start_char + \"[swearS3]\",\n",
        "    19593: word_start_char + \"[swearS4]\", # S***\n",
        "    10965: word_start_char + \"[swearF1]\", # F***\n",
        "    26154: word_start_char + \"[swearF2]\", # F***\n",
        "    33342: word_start_char + \"[swearF3]\",\n",
        "    47069: word_start_char + \"[swearF4]\", # f****\n",
        "    3275: word_start_char + \"[swearF5]\",\n",
        "    22518: word_start_char + \"[swearF6]\",\n",
        "    20022: word_start_char + \"[swearF7]\",\n",
        "    5546: word_start_char + \"[swearF8]\",\n",
        "    47069: word_start_char + \"[swearM1]\",\n",
        "    29537: word_start_char + \"[swearM2]\",\n",
        "    22676: word_start_char + \"[swearB1]\", # bull****\n",
        "    11960: word_start_char + \"[swearB2]\",\n",
        "    42094: word_start_char + \"[swearB3]\",\n",
        "    40678: word_start_char + \"[swearB4]\"\n",
        "}\n",
        "replaced_keys = set()\n",
        "\n",
        "for key in vocab:\n",
        "    token_id = vocab[key]\n",
        "    if token_id in token_id_remappings:\n",
        "        new_key = token_id_remappings[token_id]\n",
        "        new_vocab[new_key] = token_id\n",
        "        replaced_keys.add(key)\n",
        "    else:\n",
        "        new_vocab[key] = token_id\n",
        "\n",
        "new_merges = []\n",
        "with open(tokenizer_directory / 'merges.txt', 'r', encoding='utf-8') as merges:\n",
        "    for line in merges.readlines():\n",
        "        if len(line) == 0:\n",
        "            continue\n",
        "        words = split_by_word(line)\n",
        "        if not (words[0] in replaced_keys):\n",
        "            new_merges.append(line.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKCuKjtPIRaR"
      },
      "source": [
        "To check for other indexes to replace (keeping in mind that the output should still be multi-lingual), we could do something like this:\n",
        "```python\n",
        "!pip install better_profanity==0.7.0\n",
        "\n",
        "from better_profanity import profanity\n",
        "\n",
        "profanity.load_censor_words()\n",
        "for key in new_vocab:\n",
        "    word = key\n",
        "    if key.startswith(word_start_char):\n",
        "        word = key[1:]\n",
        "    if profanity.contains_profanity(word):\n",
        "        print(\"Consider replacing\", key, new_vocab[key])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhNhzp98FjFR"
      },
      "outputs": [],
      "source": [
        "# !pip install better_profanity==0.7.0\n",
        "\n",
        "# from better_profanity import profanity\n",
        "\n",
        "# profanity.load_censor_words()\n",
        "# for key in new_vocab:\n",
        "#     word = key\n",
        "#     if key.startswith(word_start_char):\n",
        "#         word = key[1:]\n",
        "#     if profanity.contains_profanity(word):\n",
        "#         print(\"Consider replacing\", key, new_vocab[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_lDgRsIuLRY"
      },
      "source": [
        "Great! We now have an updated vocab file!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xa4M3M_02GwI"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Write to a file\n",
        "tokenizer_fr_directory = Path('updated-tokenizer')\n",
        "if tokenizer_fr_directory.exists():\n",
        "    shutil.rmtree(tokenizer_fr_directory)\n",
        "shutil.copytree(tokenizer_directory, tokenizer_fr_directory)\n",
        "with open(tokenizer_fr_directory / 'vocab.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(new_vocab, f, ensure_ascii=False)\n",
        "\n",
        "\n",
        "with open(tokenizer_fr_directory / 'merges.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n'.join(new_merges))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oSULQLZz5rQ",
        "outputId": "a02fa66b-38ce-4d5b-be6d-481066a901d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "105"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import WhisperTokenizer\n",
        "\n",
        "# Use a normal WhisperTokenizer -- WhisperTokenizerFast has trouble with the updated\n",
        "# vocabulary.\n",
        "tokenizer = WhisperTokenizer(\n",
        "    tokenizer_fr_directory / 'vocab.json',\n",
        "    tokenizer_fr_directory / 'merges.txt',\n",
        "    tokenizer_fr_directory / 'normalizer.json',\n",
        "    bos_token='<|startoftranscript|>',\n",
        "    unk_token='',\n",
        "    pad_token='<|endoftext|>',\n",
        ")\n",
        "\n",
        "# See https://discuss.huggingface.co/t/fine-tuning-whisper-on-my-own-dataset-with-a-customized-tokenizer/25903\n",
        "tokenizer.add_special_tokens(tokenizer_original.special_tokens_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl_cU43c7IHR",
        "outputId": "1b5d6c33-ad38-457d-ec14-7af7acff9afc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('updated-tokenizer/tokenizer_config.json',\n",
              " 'updated-tokenizer/special_tokens_map.json',\n",
              " 'updated-tokenizer/vocab.json',\n",
              " 'updated-tokenizer/merges.txt',\n",
              " 'updated-tokenizer/normalizer.json',\n",
              " 'updated-tokenizer/added_tokens.json')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# For debugging, update the output directory\n",
        "shutil.rmtree(tokenizer_fr_directory)\n",
        "tokenizer.save_pretrained(tokenizer_fr_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMpuESBPSRs6"
      },
      "source": [
        "Next, build the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAjMqolA-957",
        "outputId": "01d3b331-c112-4f95-f09f-1c08e82bcca4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/final-model/tokenizer_config.json',\n",
              " '/content/final-model/special_tokens_map.json',\n",
              " '/content/final-model/vocab.json',\n",
              " '/content/final-model/merges.txt',\n",
              " '/content/final-model/normalizer.json',\n",
              " '/content/final-model/added_tokens.json')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_output_dir = Path('./final-model').resolve()\n",
        "model.save_pretrained(model_output_dir)\n",
        "tokenizer.save_pretrained(model_output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CINj6diwNUg3"
      },
      "source": [
        "We can now convert the model to GGML:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAjkv32aNUzW",
        "outputId": "ada6f6e9-dacd-4847-a325-c61b5543cb89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-03-25 19:14:05.706870: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742930045.728506   15587 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742930045.739139   15587 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "model.encoder.conv1.weight  ->  encoder.conv1.weight\n",
            "encoder.conv1.weight 3 (512, 80, 3)\n",
            "model.encoder.conv1.bias  ->  encoder.conv1.bias\n",
            "  Reshaped variable:  encoder.conv1.bias  to shape:  (512, 1)\n",
            "encoder.conv1.bias 2 (512, 1)\n",
            "  Converting to float32\n",
            "model.encoder.conv2.weight  ->  encoder.conv2.weight\n",
            "encoder.conv2.weight 3 (512, 512, 3)\n",
            "model.encoder.conv2.bias  ->  encoder.conv2.bias\n",
            "  Reshaped variable:  encoder.conv2.bias  to shape:  (512, 1)\n",
            "encoder.conv2.bias 2 (512, 1)\n",
            "  Converting to float32\n",
            "model.encoder.embed_positions.weight  ->  encoder.positional_embedding\n",
            "encoder.positional_embedding 2 (1500, 512)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.self_attn.k_proj.weight  ->  encoder.blocks.0.attn.key.weight\n",
            "encoder.blocks.0.attn.key.weight 2 (512, 512)\n",
            "model.encoder.layers.0.self_attn.v_proj.weight  ->  encoder.blocks.0.attn.value.weight\n",
            "encoder.blocks.0.attn.value.weight 2 (512, 512)\n",
            "model.encoder.layers.0.self_attn.v_proj.bias  ->  encoder.blocks.0.attn.value.bias\n",
            "encoder.blocks.0.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.self_attn.q_proj.weight  ->  encoder.blocks.0.attn.query.weight\n",
            "encoder.blocks.0.attn.query.weight 2 (512, 512)\n",
            "model.encoder.layers.0.self_attn.q_proj.bias  ->  encoder.blocks.0.attn.query.bias\n",
            "encoder.blocks.0.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.self_attn.out_proj.weight  ->  encoder.blocks.0.attn.out.weight\n",
            "encoder.blocks.0.attn.out.weight 2 (512, 512)\n",
            "model.encoder.layers.0.self_attn.out_proj.bias  ->  encoder.blocks.0.attn.out.bias\n",
            "encoder.blocks.0.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.self_attn_layer_norm.weight  ->  encoder.blocks.0.attn_ln.weight\n",
            "encoder.blocks.0.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.self_attn_layer_norm.bias  ->  encoder.blocks.0.attn_ln.bias\n",
            "encoder.blocks.0.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.fc1.weight  ->  encoder.blocks.0.mlp.0.weight\n",
            "encoder.blocks.0.mlp.0.weight 2 (2048, 512)\n",
            "model.encoder.layers.0.fc1.bias  ->  encoder.blocks.0.mlp.0.bias\n",
            "encoder.blocks.0.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.fc2.weight  ->  encoder.blocks.0.mlp.2.weight\n",
            "encoder.blocks.0.mlp.2.weight 2 (512, 2048)\n",
            "model.encoder.layers.0.fc2.bias  ->  encoder.blocks.0.mlp.2.bias\n",
            "encoder.blocks.0.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.final_layer_norm.weight  ->  encoder.blocks.0.mlp_ln.weight\n",
            "encoder.blocks.0.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.0.final_layer_norm.bias  ->  encoder.blocks.0.mlp_ln.bias\n",
            "encoder.blocks.0.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.self_attn.k_proj.weight  ->  encoder.blocks.1.attn.key.weight\n",
            "encoder.blocks.1.attn.key.weight 2 (512, 512)\n",
            "model.encoder.layers.1.self_attn.v_proj.weight  ->  encoder.blocks.1.attn.value.weight\n",
            "encoder.blocks.1.attn.value.weight 2 (512, 512)\n",
            "model.encoder.layers.1.self_attn.v_proj.bias  ->  encoder.blocks.1.attn.value.bias\n",
            "encoder.blocks.1.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.self_attn.q_proj.weight  ->  encoder.blocks.1.attn.query.weight\n",
            "encoder.blocks.1.attn.query.weight 2 (512, 512)\n",
            "model.encoder.layers.1.self_attn.q_proj.bias  ->  encoder.blocks.1.attn.query.bias\n",
            "encoder.blocks.1.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.self_attn.out_proj.weight  ->  encoder.blocks.1.attn.out.weight\n",
            "encoder.blocks.1.attn.out.weight 2 (512, 512)\n",
            "model.encoder.layers.1.self_attn.out_proj.bias  ->  encoder.blocks.1.attn.out.bias\n",
            "encoder.blocks.1.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.self_attn_layer_norm.weight  ->  encoder.blocks.1.attn_ln.weight\n",
            "encoder.blocks.1.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.self_attn_layer_norm.bias  ->  encoder.blocks.1.attn_ln.bias\n",
            "encoder.blocks.1.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.fc1.weight  ->  encoder.blocks.1.mlp.0.weight\n",
            "encoder.blocks.1.mlp.0.weight 2 (2048, 512)\n",
            "model.encoder.layers.1.fc1.bias  ->  encoder.blocks.1.mlp.0.bias\n",
            "encoder.blocks.1.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.fc2.weight  ->  encoder.blocks.1.mlp.2.weight\n",
            "encoder.blocks.1.mlp.2.weight 2 (512, 2048)\n",
            "model.encoder.layers.1.fc2.bias  ->  encoder.blocks.1.mlp.2.bias\n",
            "encoder.blocks.1.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.final_layer_norm.weight  ->  encoder.blocks.1.mlp_ln.weight\n",
            "encoder.blocks.1.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.1.final_layer_norm.bias  ->  encoder.blocks.1.mlp_ln.bias\n",
            "encoder.blocks.1.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.self_attn.k_proj.weight  ->  encoder.blocks.2.attn.key.weight\n",
            "encoder.blocks.2.attn.key.weight 2 (512, 512)\n",
            "model.encoder.layers.2.self_attn.v_proj.weight  ->  encoder.blocks.2.attn.value.weight\n",
            "encoder.blocks.2.attn.value.weight 2 (512, 512)\n",
            "model.encoder.layers.2.self_attn.v_proj.bias  ->  encoder.blocks.2.attn.value.bias\n",
            "encoder.blocks.2.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.self_attn.q_proj.weight  ->  encoder.blocks.2.attn.query.weight\n",
            "encoder.blocks.2.attn.query.weight 2 (512, 512)\n",
            "model.encoder.layers.2.self_attn.q_proj.bias  ->  encoder.blocks.2.attn.query.bias\n",
            "encoder.blocks.2.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.self_attn.out_proj.weight  ->  encoder.blocks.2.attn.out.weight\n",
            "encoder.blocks.2.attn.out.weight 2 (512, 512)\n",
            "model.encoder.layers.2.self_attn.out_proj.bias  ->  encoder.blocks.2.attn.out.bias\n",
            "encoder.blocks.2.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.self_attn_layer_norm.weight  ->  encoder.blocks.2.attn_ln.weight\n",
            "encoder.blocks.2.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.self_attn_layer_norm.bias  ->  encoder.blocks.2.attn_ln.bias\n",
            "encoder.blocks.2.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.fc1.weight  ->  encoder.blocks.2.mlp.0.weight\n",
            "encoder.blocks.2.mlp.0.weight 2 (2048, 512)\n",
            "model.encoder.layers.2.fc1.bias  ->  encoder.blocks.2.mlp.0.bias\n",
            "encoder.blocks.2.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.fc2.weight  ->  encoder.blocks.2.mlp.2.weight\n",
            "encoder.blocks.2.mlp.2.weight 2 (512, 2048)\n",
            "model.encoder.layers.2.fc2.bias  ->  encoder.blocks.2.mlp.2.bias\n",
            "encoder.blocks.2.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.final_layer_norm.weight  ->  encoder.blocks.2.mlp_ln.weight\n",
            "encoder.blocks.2.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.2.final_layer_norm.bias  ->  encoder.blocks.2.mlp_ln.bias\n",
            "encoder.blocks.2.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.self_attn.k_proj.weight  ->  encoder.blocks.3.attn.key.weight\n",
            "encoder.blocks.3.attn.key.weight 2 (512, 512)\n",
            "model.encoder.layers.3.self_attn.v_proj.weight  ->  encoder.blocks.3.attn.value.weight\n",
            "encoder.blocks.3.attn.value.weight 2 (512, 512)\n",
            "model.encoder.layers.3.self_attn.v_proj.bias  ->  encoder.blocks.3.attn.value.bias\n",
            "encoder.blocks.3.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.self_attn.q_proj.weight  ->  encoder.blocks.3.attn.query.weight\n",
            "encoder.blocks.3.attn.query.weight 2 (512, 512)\n",
            "model.encoder.layers.3.self_attn.q_proj.bias  ->  encoder.blocks.3.attn.query.bias\n",
            "encoder.blocks.3.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.self_attn.out_proj.weight  ->  encoder.blocks.3.attn.out.weight\n",
            "encoder.blocks.3.attn.out.weight 2 (512, 512)\n",
            "model.encoder.layers.3.self_attn.out_proj.bias  ->  encoder.blocks.3.attn.out.bias\n",
            "encoder.blocks.3.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.self_attn_layer_norm.weight  ->  encoder.blocks.3.attn_ln.weight\n",
            "encoder.blocks.3.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.self_attn_layer_norm.bias  ->  encoder.blocks.3.attn_ln.bias\n",
            "encoder.blocks.3.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.fc1.weight  ->  encoder.blocks.3.mlp.0.weight\n",
            "encoder.blocks.3.mlp.0.weight 2 (2048, 512)\n",
            "model.encoder.layers.3.fc1.bias  ->  encoder.blocks.3.mlp.0.bias\n",
            "encoder.blocks.3.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.fc2.weight  ->  encoder.blocks.3.mlp.2.weight\n",
            "encoder.blocks.3.mlp.2.weight 2 (512, 2048)\n",
            "model.encoder.layers.3.fc2.bias  ->  encoder.blocks.3.mlp.2.bias\n",
            "encoder.blocks.3.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.final_layer_norm.weight  ->  encoder.blocks.3.mlp_ln.weight\n",
            "encoder.blocks.3.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.3.final_layer_norm.bias  ->  encoder.blocks.3.mlp_ln.bias\n",
            "encoder.blocks.3.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.self_attn.k_proj.weight  ->  encoder.blocks.4.attn.key.weight\n",
            "encoder.blocks.4.attn.key.weight 2 (512, 512)\n",
            "model.encoder.layers.4.self_attn.v_proj.weight  ->  encoder.blocks.4.attn.value.weight\n",
            "encoder.blocks.4.attn.value.weight 2 (512, 512)\n",
            "model.encoder.layers.4.self_attn.v_proj.bias  ->  encoder.blocks.4.attn.value.bias\n",
            "encoder.blocks.4.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.self_attn.q_proj.weight  ->  encoder.blocks.4.attn.query.weight\n",
            "encoder.blocks.4.attn.query.weight 2 (512, 512)\n",
            "model.encoder.layers.4.self_attn.q_proj.bias  ->  encoder.blocks.4.attn.query.bias\n",
            "encoder.blocks.4.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.self_attn.out_proj.weight  ->  encoder.blocks.4.attn.out.weight\n",
            "encoder.blocks.4.attn.out.weight 2 (512, 512)\n",
            "model.encoder.layers.4.self_attn.out_proj.bias  ->  encoder.blocks.4.attn.out.bias\n",
            "encoder.blocks.4.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.self_attn_layer_norm.weight  ->  encoder.blocks.4.attn_ln.weight\n",
            "encoder.blocks.4.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.self_attn_layer_norm.bias  ->  encoder.blocks.4.attn_ln.bias\n",
            "encoder.blocks.4.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.fc1.weight  ->  encoder.blocks.4.mlp.0.weight\n",
            "encoder.blocks.4.mlp.0.weight 2 (2048, 512)\n",
            "model.encoder.layers.4.fc1.bias  ->  encoder.blocks.4.mlp.0.bias\n",
            "encoder.blocks.4.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.fc2.weight  ->  encoder.blocks.4.mlp.2.weight\n",
            "encoder.blocks.4.mlp.2.weight 2 (512, 2048)\n",
            "model.encoder.layers.4.fc2.bias  ->  encoder.blocks.4.mlp.2.bias\n",
            "encoder.blocks.4.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.final_layer_norm.weight  ->  encoder.blocks.4.mlp_ln.weight\n",
            "encoder.blocks.4.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.4.final_layer_norm.bias  ->  encoder.blocks.4.mlp_ln.bias\n",
            "encoder.blocks.4.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.self_attn.k_proj.weight  ->  encoder.blocks.5.attn.key.weight\n",
            "encoder.blocks.5.attn.key.weight 2 (512, 512)\n",
            "model.encoder.layers.5.self_attn.v_proj.weight  ->  encoder.blocks.5.attn.value.weight\n",
            "encoder.blocks.5.attn.value.weight 2 (512, 512)\n",
            "model.encoder.layers.5.self_attn.v_proj.bias  ->  encoder.blocks.5.attn.value.bias\n",
            "encoder.blocks.5.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.self_attn.q_proj.weight  ->  encoder.blocks.5.attn.query.weight\n",
            "encoder.blocks.5.attn.query.weight 2 (512, 512)\n",
            "model.encoder.layers.5.self_attn.q_proj.bias  ->  encoder.blocks.5.attn.query.bias\n",
            "encoder.blocks.5.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.self_attn.out_proj.weight  ->  encoder.blocks.5.attn.out.weight\n",
            "encoder.blocks.5.attn.out.weight 2 (512, 512)\n",
            "model.encoder.layers.5.self_attn.out_proj.bias  ->  encoder.blocks.5.attn.out.bias\n",
            "encoder.blocks.5.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.self_attn_layer_norm.weight  ->  encoder.blocks.5.attn_ln.weight\n",
            "encoder.blocks.5.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.self_attn_layer_norm.bias  ->  encoder.blocks.5.attn_ln.bias\n",
            "encoder.blocks.5.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.fc1.weight  ->  encoder.blocks.5.mlp.0.weight\n",
            "encoder.blocks.5.mlp.0.weight 2 (2048, 512)\n",
            "model.encoder.layers.5.fc1.bias  ->  encoder.blocks.5.mlp.0.bias\n",
            "encoder.blocks.5.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.fc2.weight  ->  encoder.blocks.5.mlp.2.weight\n",
            "encoder.blocks.5.mlp.2.weight 2 (512, 2048)\n",
            "model.encoder.layers.5.fc2.bias  ->  encoder.blocks.5.mlp.2.bias\n",
            "encoder.blocks.5.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.final_layer_norm.weight  ->  encoder.blocks.5.mlp_ln.weight\n",
            "encoder.blocks.5.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layers.5.final_layer_norm.bias  ->  encoder.blocks.5.mlp_ln.bias\n",
            "encoder.blocks.5.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layer_norm.weight  ->  encoder.ln_post.weight\n",
            "encoder.ln_post.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.encoder.layer_norm.bias  ->  encoder.ln_post.bias\n",
            "encoder.ln_post.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.embed_tokens.weight  ->  decoder.token_embedding.weight\n",
            "decoder.token_embedding.weight 2 (51865, 512)\n",
            "model.decoder.embed_positions.weight  ->  decoder.positional_embedding\n",
            "decoder.positional_embedding 2 (448, 512)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.self_attn.k_proj.weight  ->  decoder.blocks.0.attn.key.weight\n",
            "decoder.blocks.0.attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.0.self_attn.v_proj.weight  ->  decoder.blocks.0.attn.value.weight\n",
            "decoder.blocks.0.attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.0.self_attn.v_proj.bias  ->  decoder.blocks.0.attn.value.bias\n",
            "decoder.blocks.0.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.self_attn.q_proj.weight  ->  decoder.blocks.0.attn.query.weight\n",
            "decoder.blocks.0.attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.0.self_attn.q_proj.bias  ->  decoder.blocks.0.attn.query.bias\n",
            "decoder.blocks.0.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.self_attn.out_proj.weight  ->  decoder.blocks.0.attn.out.weight\n",
            "decoder.blocks.0.attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.0.self_attn.out_proj.bias  ->  decoder.blocks.0.attn.out.bias\n",
            "decoder.blocks.0.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.self_attn_layer_norm.weight  ->  decoder.blocks.0.attn_ln.weight\n",
            "decoder.blocks.0.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.self_attn_layer_norm.bias  ->  decoder.blocks.0.attn_ln.bias\n",
            "decoder.blocks.0.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.encoder_attn.k_proj.weight  ->  decoder.blocks.0.cross_attn.key.weight\n",
            "decoder.blocks.0.cross_attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.0.encoder_attn.v_proj.weight  ->  decoder.blocks.0.cross_attn.value.weight\n",
            "decoder.blocks.0.cross_attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.0.encoder_attn.v_proj.bias  ->  decoder.blocks.0.cross_attn.value.bias\n",
            "decoder.blocks.0.cross_attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.encoder_attn.q_proj.weight  ->  decoder.blocks.0.cross_attn.query.weight\n",
            "decoder.blocks.0.cross_attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.0.encoder_attn.q_proj.bias  ->  decoder.blocks.0.cross_attn.query.bias\n",
            "decoder.blocks.0.cross_attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.encoder_attn.out_proj.weight  ->  decoder.blocks.0.cross_attn.out.weight\n",
            "decoder.blocks.0.cross_attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.0.encoder_attn.out_proj.bias  ->  decoder.blocks.0.cross_attn.out.bias\n",
            "decoder.blocks.0.cross_attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.weight  ->  decoder.blocks.0.cross_attn_ln.weight\n",
            "decoder.blocks.0.cross_attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.bias  ->  decoder.blocks.0.cross_attn_ln.bias\n",
            "decoder.blocks.0.cross_attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.fc1.weight  ->  decoder.blocks.0.mlp.0.weight\n",
            "decoder.blocks.0.mlp.0.weight 2 (2048, 512)\n",
            "model.decoder.layers.0.fc1.bias  ->  decoder.blocks.0.mlp.0.bias\n",
            "decoder.blocks.0.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.fc2.weight  ->  decoder.blocks.0.mlp.2.weight\n",
            "decoder.blocks.0.mlp.2.weight 2 (512, 2048)\n",
            "model.decoder.layers.0.fc2.bias  ->  decoder.blocks.0.mlp.2.bias\n",
            "decoder.blocks.0.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.final_layer_norm.weight  ->  decoder.blocks.0.mlp_ln.weight\n",
            "decoder.blocks.0.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.0.final_layer_norm.bias  ->  decoder.blocks.0.mlp_ln.bias\n",
            "decoder.blocks.0.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.self_attn.k_proj.weight  ->  decoder.blocks.1.attn.key.weight\n",
            "decoder.blocks.1.attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.1.self_attn.v_proj.weight  ->  decoder.blocks.1.attn.value.weight\n",
            "decoder.blocks.1.attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.1.self_attn.v_proj.bias  ->  decoder.blocks.1.attn.value.bias\n",
            "decoder.blocks.1.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.self_attn.q_proj.weight  ->  decoder.blocks.1.attn.query.weight\n",
            "decoder.blocks.1.attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.1.self_attn.q_proj.bias  ->  decoder.blocks.1.attn.query.bias\n",
            "decoder.blocks.1.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.self_attn.out_proj.weight  ->  decoder.blocks.1.attn.out.weight\n",
            "decoder.blocks.1.attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.1.self_attn.out_proj.bias  ->  decoder.blocks.1.attn.out.bias\n",
            "decoder.blocks.1.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.self_attn_layer_norm.weight  ->  decoder.blocks.1.attn_ln.weight\n",
            "decoder.blocks.1.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.self_attn_layer_norm.bias  ->  decoder.blocks.1.attn_ln.bias\n",
            "decoder.blocks.1.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.encoder_attn.k_proj.weight  ->  decoder.blocks.1.cross_attn.key.weight\n",
            "decoder.blocks.1.cross_attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.1.encoder_attn.v_proj.weight  ->  decoder.blocks.1.cross_attn.value.weight\n",
            "decoder.blocks.1.cross_attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.1.encoder_attn.v_proj.bias  ->  decoder.blocks.1.cross_attn.value.bias\n",
            "decoder.blocks.1.cross_attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.encoder_attn.q_proj.weight  ->  decoder.blocks.1.cross_attn.query.weight\n",
            "decoder.blocks.1.cross_attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.1.encoder_attn.q_proj.bias  ->  decoder.blocks.1.cross_attn.query.bias\n",
            "decoder.blocks.1.cross_attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.encoder_attn.out_proj.weight  ->  decoder.blocks.1.cross_attn.out.weight\n",
            "decoder.blocks.1.cross_attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.1.encoder_attn.out_proj.bias  ->  decoder.blocks.1.cross_attn.out.bias\n",
            "decoder.blocks.1.cross_attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.weight  ->  decoder.blocks.1.cross_attn_ln.weight\n",
            "decoder.blocks.1.cross_attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.bias  ->  decoder.blocks.1.cross_attn_ln.bias\n",
            "decoder.blocks.1.cross_attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.fc1.weight  ->  decoder.blocks.1.mlp.0.weight\n",
            "decoder.blocks.1.mlp.0.weight 2 (2048, 512)\n",
            "model.decoder.layers.1.fc1.bias  ->  decoder.blocks.1.mlp.0.bias\n",
            "decoder.blocks.1.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.fc2.weight  ->  decoder.blocks.1.mlp.2.weight\n",
            "decoder.blocks.1.mlp.2.weight 2 (512, 2048)\n",
            "model.decoder.layers.1.fc2.bias  ->  decoder.blocks.1.mlp.2.bias\n",
            "decoder.blocks.1.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.final_layer_norm.weight  ->  decoder.blocks.1.mlp_ln.weight\n",
            "decoder.blocks.1.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.1.final_layer_norm.bias  ->  decoder.blocks.1.mlp_ln.bias\n",
            "decoder.blocks.1.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.self_attn.k_proj.weight  ->  decoder.blocks.2.attn.key.weight\n",
            "decoder.blocks.2.attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.2.self_attn.v_proj.weight  ->  decoder.blocks.2.attn.value.weight\n",
            "decoder.blocks.2.attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.2.self_attn.v_proj.bias  ->  decoder.blocks.2.attn.value.bias\n",
            "decoder.blocks.2.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.self_attn.q_proj.weight  ->  decoder.blocks.2.attn.query.weight\n",
            "decoder.blocks.2.attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.2.self_attn.q_proj.bias  ->  decoder.blocks.2.attn.query.bias\n",
            "decoder.blocks.2.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.self_attn.out_proj.weight  ->  decoder.blocks.2.attn.out.weight\n",
            "decoder.blocks.2.attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.2.self_attn.out_proj.bias  ->  decoder.blocks.2.attn.out.bias\n",
            "decoder.blocks.2.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.self_attn_layer_norm.weight  ->  decoder.blocks.2.attn_ln.weight\n",
            "decoder.blocks.2.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.self_attn_layer_norm.bias  ->  decoder.blocks.2.attn_ln.bias\n",
            "decoder.blocks.2.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.encoder_attn.k_proj.weight  ->  decoder.blocks.2.cross_attn.key.weight\n",
            "decoder.blocks.2.cross_attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.2.encoder_attn.v_proj.weight  ->  decoder.blocks.2.cross_attn.value.weight\n",
            "decoder.blocks.2.cross_attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.2.encoder_attn.v_proj.bias  ->  decoder.blocks.2.cross_attn.value.bias\n",
            "decoder.blocks.2.cross_attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.encoder_attn.q_proj.weight  ->  decoder.blocks.2.cross_attn.query.weight\n",
            "decoder.blocks.2.cross_attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.2.encoder_attn.q_proj.bias  ->  decoder.blocks.2.cross_attn.query.bias\n",
            "decoder.blocks.2.cross_attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.encoder_attn.out_proj.weight  ->  decoder.blocks.2.cross_attn.out.weight\n",
            "decoder.blocks.2.cross_attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.2.encoder_attn.out_proj.bias  ->  decoder.blocks.2.cross_attn.out.bias\n",
            "decoder.blocks.2.cross_attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.weight  ->  decoder.blocks.2.cross_attn_ln.weight\n",
            "decoder.blocks.2.cross_attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.bias  ->  decoder.blocks.2.cross_attn_ln.bias\n",
            "decoder.blocks.2.cross_attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.fc1.weight  ->  decoder.blocks.2.mlp.0.weight\n",
            "decoder.blocks.2.mlp.0.weight 2 (2048, 512)\n",
            "model.decoder.layers.2.fc1.bias  ->  decoder.blocks.2.mlp.0.bias\n",
            "decoder.blocks.2.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.fc2.weight  ->  decoder.blocks.2.mlp.2.weight\n",
            "decoder.blocks.2.mlp.2.weight 2 (512, 2048)\n",
            "model.decoder.layers.2.fc2.bias  ->  decoder.blocks.2.mlp.2.bias\n",
            "decoder.blocks.2.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.final_layer_norm.weight  ->  decoder.blocks.2.mlp_ln.weight\n",
            "decoder.blocks.2.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.2.final_layer_norm.bias  ->  decoder.blocks.2.mlp_ln.bias\n",
            "decoder.blocks.2.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.self_attn.k_proj.weight  ->  decoder.blocks.3.attn.key.weight\n",
            "decoder.blocks.3.attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.3.self_attn.v_proj.weight  ->  decoder.blocks.3.attn.value.weight\n",
            "decoder.blocks.3.attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.3.self_attn.v_proj.bias  ->  decoder.blocks.3.attn.value.bias\n",
            "decoder.blocks.3.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.self_attn.q_proj.weight  ->  decoder.blocks.3.attn.query.weight\n",
            "decoder.blocks.3.attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.3.self_attn.q_proj.bias  ->  decoder.blocks.3.attn.query.bias\n",
            "decoder.blocks.3.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.self_attn.out_proj.weight  ->  decoder.blocks.3.attn.out.weight\n",
            "decoder.blocks.3.attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.3.self_attn.out_proj.bias  ->  decoder.blocks.3.attn.out.bias\n",
            "decoder.blocks.3.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.self_attn_layer_norm.weight  ->  decoder.blocks.3.attn_ln.weight\n",
            "decoder.blocks.3.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.self_attn_layer_norm.bias  ->  decoder.blocks.3.attn_ln.bias\n",
            "decoder.blocks.3.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.encoder_attn.k_proj.weight  ->  decoder.blocks.3.cross_attn.key.weight\n",
            "decoder.blocks.3.cross_attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.3.encoder_attn.v_proj.weight  ->  decoder.blocks.3.cross_attn.value.weight\n",
            "decoder.blocks.3.cross_attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.3.encoder_attn.v_proj.bias  ->  decoder.blocks.3.cross_attn.value.bias\n",
            "decoder.blocks.3.cross_attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.encoder_attn.q_proj.weight  ->  decoder.blocks.3.cross_attn.query.weight\n",
            "decoder.blocks.3.cross_attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.3.encoder_attn.q_proj.bias  ->  decoder.blocks.3.cross_attn.query.bias\n",
            "decoder.blocks.3.cross_attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.encoder_attn.out_proj.weight  ->  decoder.blocks.3.cross_attn.out.weight\n",
            "decoder.blocks.3.cross_attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.3.encoder_attn.out_proj.bias  ->  decoder.blocks.3.cross_attn.out.bias\n",
            "decoder.blocks.3.cross_attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.weight  ->  decoder.blocks.3.cross_attn_ln.weight\n",
            "decoder.blocks.3.cross_attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.bias  ->  decoder.blocks.3.cross_attn_ln.bias\n",
            "decoder.blocks.3.cross_attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.fc1.weight  ->  decoder.blocks.3.mlp.0.weight\n",
            "decoder.blocks.3.mlp.0.weight 2 (2048, 512)\n",
            "model.decoder.layers.3.fc1.bias  ->  decoder.blocks.3.mlp.0.bias\n",
            "decoder.blocks.3.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.fc2.weight  ->  decoder.blocks.3.mlp.2.weight\n",
            "decoder.blocks.3.mlp.2.weight 2 (512, 2048)\n",
            "model.decoder.layers.3.fc2.bias  ->  decoder.blocks.3.mlp.2.bias\n",
            "decoder.blocks.3.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.final_layer_norm.weight  ->  decoder.blocks.3.mlp_ln.weight\n",
            "decoder.blocks.3.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.3.final_layer_norm.bias  ->  decoder.blocks.3.mlp_ln.bias\n",
            "decoder.blocks.3.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.self_attn.k_proj.weight  ->  decoder.blocks.4.attn.key.weight\n",
            "decoder.blocks.4.attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.4.self_attn.v_proj.weight  ->  decoder.blocks.4.attn.value.weight\n",
            "decoder.blocks.4.attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.4.self_attn.v_proj.bias  ->  decoder.blocks.4.attn.value.bias\n",
            "decoder.blocks.4.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.self_attn.q_proj.weight  ->  decoder.blocks.4.attn.query.weight\n",
            "decoder.blocks.4.attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.4.self_attn.q_proj.bias  ->  decoder.blocks.4.attn.query.bias\n",
            "decoder.blocks.4.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.self_attn.out_proj.weight  ->  decoder.blocks.4.attn.out.weight\n",
            "decoder.blocks.4.attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.4.self_attn.out_proj.bias  ->  decoder.blocks.4.attn.out.bias\n",
            "decoder.blocks.4.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.self_attn_layer_norm.weight  ->  decoder.blocks.4.attn_ln.weight\n",
            "decoder.blocks.4.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.self_attn_layer_norm.bias  ->  decoder.blocks.4.attn_ln.bias\n",
            "decoder.blocks.4.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.encoder_attn.k_proj.weight  ->  decoder.blocks.4.cross_attn.key.weight\n",
            "decoder.blocks.4.cross_attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.4.encoder_attn.v_proj.weight  ->  decoder.blocks.4.cross_attn.value.weight\n",
            "decoder.blocks.4.cross_attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.4.encoder_attn.v_proj.bias  ->  decoder.blocks.4.cross_attn.value.bias\n",
            "decoder.blocks.4.cross_attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.encoder_attn.q_proj.weight  ->  decoder.blocks.4.cross_attn.query.weight\n",
            "decoder.blocks.4.cross_attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.4.encoder_attn.q_proj.bias  ->  decoder.blocks.4.cross_attn.query.bias\n",
            "decoder.blocks.4.cross_attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.encoder_attn.out_proj.weight  ->  decoder.blocks.4.cross_attn.out.weight\n",
            "decoder.blocks.4.cross_attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.4.encoder_attn.out_proj.bias  ->  decoder.blocks.4.cross_attn.out.bias\n",
            "decoder.blocks.4.cross_attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.weight  ->  decoder.blocks.4.cross_attn_ln.weight\n",
            "decoder.blocks.4.cross_attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.bias  ->  decoder.blocks.4.cross_attn_ln.bias\n",
            "decoder.blocks.4.cross_attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.fc1.weight  ->  decoder.blocks.4.mlp.0.weight\n",
            "decoder.blocks.4.mlp.0.weight 2 (2048, 512)\n",
            "model.decoder.layers.4.fc1.bias  ->  decoder.blocks.4.mlp.0.bias\n",
            "decoder.blocks.4.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.fc2.weight  ->  decoder.blocks.4.mlp.2.weight\n",
            "decoder.blocks.4.mlp.2.weight 2 (512, 2048)\n",
            "model.decoder.layers.4.fc2.bias  ->  decoder.blocks.4.mlp.2.bias\n",
            "decoder.blocks.4.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.final_layer_norm.weight  ->  decoder.blocks.4.mlp_ln.weight\n",
            "decoder.blocks.4.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.4.final_layer_norm.bias  ->  decoder.blocks.4.mlp_ln.bias\n",
            "decoder.blocks.4.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.self_attn.k_proj.weight  ->  decoder.blocks.5.attn.key.weight\n",
            "decoder.blocks.5.attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.5.self_attn.v_proj.weight  ->  decoder.blocks.5.attn.value.weight\n",
            "decoder.blocks.5.attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.5.self_attn.v_proj.bias  ->  decoder.blocks.5.attn.value.bias\n",
            "decoder.blocks.5.attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.self_attn.q_proj.weight  ->  decoder.blocks.5.attn.query.weight\n",
            "decoder.blocks.5.attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.5.self_attn.q_proj.bias  ->  decoder.blocks.5.attn.query.bias\n",
            "decoder.blocks.5.attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.self_attn.out_proj.weight  ->  decoder.blocks.5.attn.out.weight\n",
            "decoder.blocks.5.attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.5.self_attn.out_proj.bias  ->  decoder.blocks.5.attn.out.bias\n",
            "decoder.blocks.5.attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.self_attn_layer_norm.weight  ->  decoder.blocks.5.attn_ln.weight\n",
            "decoder.blocks.5.attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.self_attn_layer_norm.bias  ->  decoder.blocks.5.attn_ln.bias\n",
            "decoder.blocks.5.attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.encoder_attn.k_proj.weight  ->  decoder.blocks.5.cross_attn.key.weight\n",
            "decoder.blocks.5.cross_attn.key.weight 2 (512, 512)\n",
            "model.decoder.layers.5.encoder_attn.v_proj.weight  ->  decoder.blocks.5.cross_attn.value.weight\n",
            "decoder.blocks.5.cross_attn.value.weight 2 (512, 512)\n",
            "model.decoder.layers.5.encoder_attn.v_proj.bias  ->  decoder.blocks.5.cross_attn.value.bias\n",
            "decoder.blocks.5.cross_attn.value.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.encoder_attn.q_proj.weight  ->  decoder.blocks.5.cross_attn.query.weight\n",
            "decoder.blocks.5.cross_attn.query.weight 2 (512, 512)\n",
            "model.decoder.layers.5.encoder_attn.q_proj.bias  ->  decoder.blocks.5.cross_attn.query.bias\n",
            "decoder.blocks.5.cross_attn.query.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.encoder_attn.out_proj.weight  ->  decoder.blocks.5.cross_attn.out.weight\n",
            "decoder.blocks.5.cross_attn.out.weight 2 (512, 512)\n",
            "model.decoder.layers.5.encoder_attn.out_proj.bias  ->  decoder.blocks.5.cross_attn.out.bias\n",
            "decoder.blocks.5.cross_attn.out.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.weight  ->  decoder.blocks.5.cross_attn_ln.weight\n",
            "decoder.blocks.5.cross_attn_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.bias  ->  decoder.blocks.5.cross_attn_ln.bias\n",
            "decoder.blocks.5.cross_attn_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.fc1.weight  ->  decoder.blocks.5.mlp.0.weight\n",
            "decoder.blocks.5.mlp.0.weight 2 (2048, 512)\n",
            "model.decoder.layers.5.fc1.bias  ->  decoder.blocks.5.mlp.0.bias\n",
            "decoder.blocks.5.mlp.0.bias 1 (2048,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.fc2.weight  ->  decoder.blocks.5.mlp.2.weight\n",
            "decoder.blocks.5.mlp.2.weight 2 (512, 2048)\n",
            "model.decoder.layers.5.fc2.bias  ->  decoder.blocks.5.mlp.2.bias\n",
            "decoder.blocks.5.mlp.2.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.final_layer_norm.weight  ->  decoder.blocks.5.mlp_ln.weight\n",
            "decoder.blocks.5.mlp_ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layers.5.final_layer_norm.bias  ->  decoder.blocks.5.mlp_ln.bias\n",
            "decoder.blocks.5.mlp_ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layer_norm.weight  ->  decoder.ln.weight\n",
            "decoder.ln.weight 1 (512,)\n",
            "  Converting to float32\n",
            "model.decoder.layer_norm.bias  ->  decoder.ln.bias\n",
            "decoder.ln.bias 1 (512,)\n",
            "  Converting to float32\n",
            "Skipping proj_out.weight\n",
            "Done. Output file:  ggml-updated/ggml-model.bin\n",
            "\n",
            "whisper_model_quantize: loading model from './ggml-updated/ggml-model.bin'\n",
            "whisper_model_quantize: n_vocab       = 51865\n",
            "whisper_model_quantize: n_audio_ctx   = 1500\n",
            "whisper_model_quantize: n_audio_state = 512\n",
            "whisper_model_quantize: n_audio_head  = 8\n",
            "whisper_model_quantize: n_audio_layer = 6\n",
            "whisper_model_quantize: n_text_ctx    = 448\n",
            "whisper_model_quantize: n_text_state  = 512\n",
            "whisper_model_quantize: n_text_head   = 8\n",
            "whisper_model_quantize: n_text_layer  = 6\n",
            "whisper_model_quantize: n_mels        = 80\n",
            "whisper_model_quantize: ftype (src)   = 1\n",
            "whisper_model_quantize: qntvr (src)   = 0\n",
            "whisper_model_quantize: ftype (dst)   = 2007\n",
            "whisper_model_quantize: qntvr (dst)   = 2\n",
            "                                            encoder.conv1.weight - [    3,    80,   512], type =    f16 size =    0.234 MB\n",
            "                                              encoder.conv1.bias - [    1,   512,     1], type =    f32 size =    0.002 MB\n",
            "                                            encoder.conv2.weight - [    3,   512,   512], type =    f16 size =    1.500 MB\n",
            "                                              encoder.conv2.bias - [    1,   512,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.positional_embedding - [  512,  1500,     1], type =    f32 size =    2.930 MB\n",
            "                                encoder.blocks.0.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              encoder.blocks.0.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.0.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.0.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.0.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.0.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  encoder.blocks.0.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.0.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.0.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.0.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.0.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.0.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.0.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.0.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.0.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.1.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              encoder.blocks.1.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.1.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.1.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.1.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.1.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  encoder.blocks.1.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.1.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.1.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.1.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.1.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.1.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.1.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.1.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.1.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.2.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              encoder.blocks.2.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.2.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.2.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.2.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.2.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  encoder.blocks.2.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.2.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.2.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.2.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.2.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.2.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.2.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.2.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.2.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.3.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              encoder.blocks.3.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.3.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.3.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.3.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.3.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  encoder.blocks.3.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.3.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.3.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.3.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.3.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.3.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.3.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.3.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.3.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.4.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              encoder.blocks.4.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.4.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.4.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.4.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.4.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  encoder.blocks.4.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.4.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.4.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.4.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.4.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.4.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.4.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.4.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.4.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.5.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              encoder.blocks.5.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.5.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.5.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                encoder.blocks.5.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.5.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  encoder.blocks.5.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.5.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.5.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.5.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.5.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.5.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     encoder.blocks.5.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.5.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.5.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                          encoder.ln_post.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                            encoder.ln_post.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.token_embedding.weight - [  512, 51865,     1], type =    f16 size =   101.30 MB ->    26.91 MB\n",
            "                                    decoder.positional_embedding - [  512,   448,     1], type =    f32 size =    0.875 MB\n",
            "                                decoder.blocks.0.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              decoder.blocks.0.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.0.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.0.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.0.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.0.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  decoder.blocks.0.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.0.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.0.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.0.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                        decoder.blocks.0.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.0.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.0.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.0.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.0.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                            decoder.blocks.0.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.0.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.0.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.0.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.0.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.0.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.0.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.0.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.0.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.1.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              decoder.blocks.1.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.1.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.1.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.1.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.1.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  decoder.blocks.1.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.1.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.1.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.1.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                        decoder.blocks.1.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.1.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.1.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.1.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.1.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                            decoder.blocks.1.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.1.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.1.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.1.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.1.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.1.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.1.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.1.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.1.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.2.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              decoder.blocks.2.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.2.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.2.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.2.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.2.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  decoder.blocks.2.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.2.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.2.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.2.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                        decoder.blocks.2.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.2.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.2.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.2.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.2.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                            decoder.blocks.2.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.2.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.2.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.2.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.2.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.2.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.2.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.2.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.2.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.3.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              decoder.blocks.3.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.3.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.3.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.3.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.3.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  decoder.blocks.3.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.3.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.3.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.3.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                        decoder.blocks.3.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.3.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.3.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.3.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.3.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                            decoder.blocks.3.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.3.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.3.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.3.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.3.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.3.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.3.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.3.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.3.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.4.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              decoder.blocks.4.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.4.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.4.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.4.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.4.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  decoder.blocks.4.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.4.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.4.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.4.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                        decoder.blocks.4.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.4.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.4.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.4.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.4.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                            decoder.blocks.4.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.4.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.4.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.4.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.4.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.4.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.4.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.4.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.4.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.5.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                              decoder.blocks.5.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.5.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.5.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                decoder.blocks.5.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.5.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                                  decoder.blocks.5.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.5.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.5.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.5.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                        decoder.blocks.5.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.5.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.5.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                          decoder.blocks.5.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.5.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.27 MB\n",
            "                            decoder.blocks.5.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.5.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.5.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.5.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.5.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.5.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     1.06 MB\n",
            "                                     decoder.blocks.5.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.5.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.5.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                               decoder.ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                                 decoder.ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "ggml_common_quantize_0: model size  =   276.92 MB\n",
            "ggml_common_quantize_0: quant size  =    77.42 MB | ftype = 7 (q8_0)\n",
            "\n",
            "main: quantize time =   974.90 ms\n",
            "main:    total time =   974.90 ms\n",
            "whisper_model_quantize: loading model from './ggml-updated/ggml-model.bin'\n",
            "whisper_model_quantize: n_vocab       = 51865\n",
            "whisper_model_quantize: n_audio_ctx   = 1500\n",
            "whisper_model_quantize: n_audio_state = 512\n",
            "whisper_model_quantize: n_audio_head  = 8\n",
            "whisper_model_quantize: n_audio_layer = 6\n",
            "whisper_model_quantize: n_text_ctx    = 448\n",
            "whisper_model_quantize: n_text_state  = 512\n",
            "whisper_model_quantize: n_text_head   = 8\n",
            "whisper_model_quantize: n_text_layer  = 6\n",
            "whisper_model_quantize: n_mels        = 80\n",
            "whisper_model_quantize: ftype (src)   = 1\n",
            "whisper_model_quantize: qntvr (src)   = 0\n",
            "whisper_model_quantize: ftype (dst)   = 2008\n",
            "whisper_model_quantize: qntvr (dst)   = 2\n",
            "                                            encoder.conv1.weight - [    3,    80,   512], type =    f16 size =    0.234 MB\n",
            "                                              encoder.conv1.bias - [    1,   512,     1], type =    f32 size =    0.002 MB\n",
            "                                            encoder.conv2.weight - [    3,   512,   512], type =    f16 size =    1.500 MB\n",
            "                                              encoder.conv2.bias - [    1,   512,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.positional_embedding - [  512,  1500,     1], type =    f32 size =    2.930 MB\n",
            "                                encoder.blocks.0.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              encoder.blocks.0.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.0.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.0.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.0.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.0.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  encoder.blocks.0.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.0.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.0.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.0.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.0.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.0.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.0.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.0.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.0.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.1.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              encoder.blocks.1.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.1.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.1.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.1.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.1.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  encoder.blocks.1.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.1.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.1.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.1.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.1.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.1.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.1.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.1.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.1.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.2.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              encoder.blocks.2.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.2.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.2.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.2.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.2.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  encoder.blocks.2.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.2.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.2.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.2.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.2.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.2.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.2.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.2.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.2.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.3.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              encoder.blocks.3.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.3.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.3.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.3.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.3.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  encoder.blocks.3.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.3.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.3.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.3.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.3.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.3.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.3.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.3.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.3.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.4.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              encoder.blocks.4.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.4.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.4.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.4.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.4.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  encoder.blocks.4.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.4.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.4.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.4.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.4.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.4.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.4.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.4.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.4.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.5.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              encoder.blocks.5.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.5.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.5.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                encoder.blocks.5.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.5.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  encoder.blocks.5.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.5.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.5.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.5.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.5.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.5.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     encoder.blocks.5.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.5.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.5.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                          encoder.ln_post.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                            encoder.ln_post.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.token_embedding.weight - [  512, 51865,     1], type =    f16 size =   101.30 MB ->    17.41 MB\n",
            "                                    decoder.positional_embedding - [  512,   448,     1], type =    f32 size =    0.875 MB\n",
            "                                decoder.blocks.0.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              decoder.blocks.0.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.0.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.0.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.0.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.0.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  decoder.blocks.0.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.0.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.0.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.0.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                        decoder.blocks.0.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.0.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.0.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.0.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.0.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                            decoder.blocks.0.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.0.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.0.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.0.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.0.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.0.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.0.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.0.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.0.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.1.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              decoder.blocks.1.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.1.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.1.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.1.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.1.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  decoder.blocks.1.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.1.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.1.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.1.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                        decoder.blocks.1.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.1.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.1.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.1.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.1.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                            decoder.blocks.1.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.1.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.1.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.1.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.1.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.1.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.1.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.1.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.1.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.2.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              decoder.blocks.2.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.2.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.2.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.2.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.2.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  decoder.blocks.2.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.2.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.2.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.2.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                        decoder.blocks.2.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.2.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.2.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.2.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.2.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                            decoder.blocks.2.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.2.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.2.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.2.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.2.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.2.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.2.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.2.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.2.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.3.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              decoder.blocks.3.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.3.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.3.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.3.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.3.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  decoder.blocks.3.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.3.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.3.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.3.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                        decoder.blocks.3.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.3.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.3.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.3.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.3.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                            decoder.blocks.3.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.3.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.3.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.3.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.3.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.3.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.3.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.3.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.3.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.4.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              decoder.blocks.4.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.4.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.4.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.4.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.4.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  decoder.blocks.4.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.4.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.4.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.4.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                        decoder.blocks.4.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.4.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.4.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.4.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.4.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                            decoder.blocks.4.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.4.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.4.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.4.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.4.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.4.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.4.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.4.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.4.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.5.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                              decoder.blocks.5.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.5.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.5.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                decoder.blocks.5.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.5.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                                  decoder.blocks.5.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.5.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.5.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.5.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                        decoder.blocks.5.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.5.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.5.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                          decoder.blocks.5.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.5.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.17 MB\n",
            "                            decoder.blocks.5.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.5.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.5.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.5.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.5.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.5.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.69 MB\n",
            "                                     decoder.blocks.5.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.5.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.5.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                               decoder.ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                                 decoder.ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "ggml_common_quantize_0: model size  =   276.92 MB\n",
            "ggml_common_quantize_0: quant size  =    52.18 MB | ftype = 8 (q5_0)\n",
            "\n",
            "main: quantize time =   795.34 ms\n",
            "main:    total time =   795.34 ms\n",
            "whisper_model_quantize: loading model from './ggml-updated/ggml-model.bin'\n",
            "whisper_model_quantize: n_vocab       = 51865\n",
            "whisper_model_quantize: n_audio_ctx   = 1500\n",
            "whisper_model_quantize: n_audio_state = 512\n",
            "whisper_model_quantize: n_audio_head  = 8\n",
            "whisper_model_quantize: n_audio_layer = 6\n",
            "whisper_model_quantize: n_text_ctx    = 448\n",
            "whisper_model_quantize: n_text_state  = 512\n",
            "whisper_model_quantize: n_text_head   = 8\n",
            "whisper_model_quantize: n_text_layer  = 6\n",
            "whisper_model_quantize: n_mels        = 80\n",
            "whisper_model_quantize: ftype (src)   = 1\n",
            "whisper_model_quantize: qntvr (src)   = 0\n",
            "whisper_model_quantize: ftype (dst)   = 2002\n",
            "whisper_model_quantize: qntvr (dst)   = 2\n",
            "                                            encoder.conv1.weight - [    3,    80,   512], type =    f16 size =    0.234 MB\n",
            "                                              encoder.conv1.bias - [    1,   512,     1], type =    f32 size =    0.002 MB\n",
            "                                            encoder.conv2.weight - [    3,   512,   512], type =    f16 size =    1.500 MB\n",
            "                                              encoder.conv2.bias - [    1,   512,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.positional_embedding - [  512,  1500,     1], type =    f32 size =    2.930 MB\n",
            "                                encoder.blocks.0.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                              encoder.blocks.0.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                encoder.blocks.0.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.0.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                encoder.blocks.0.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.0.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                  encoder.blocks.0.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.0.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.0.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.0.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     encoder.blocks.0.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.0.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     encoder.blocks.0.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.0.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.0.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.1.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                              encoder.blocks.1.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                encoder.blocks.1.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.1.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                encoder.blocks.1.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.1.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                  encoder.blocks.1.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.1.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.1.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.1.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     encoder.blocks.1.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.1.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     encoder.blocks.1.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.1.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.1.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.2.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                              encoder.blocks.2.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                encoder.blocks.2.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.2.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                encoder.blocks.2.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.2.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                  encoder.blocks.2.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.2.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.2.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.2.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     encoder.blocks.2.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.2.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     encoder.blocks.2.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.2.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.2.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.3.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                              encoder.blocks.3.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                encoder.blocks.3.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.3.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                encoder.blocks.3.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.3.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                  encoder.blocks.3.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.3.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.3.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.3.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     encoder.blocks.3.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.3.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     encoder.blocks.3.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.3.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.3.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.4.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                              encoder.blocks.4.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                encoder.blocks.4.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.4.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                encoder.blocks.4.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.4.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                  encoder.blocks.4.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.4.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.4.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.4.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     encoder.blocks.4.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.4.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     encoder.blocks.4.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.4.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.4.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.5.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                              encoder.blocks.5.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                encoder.blocks.5.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              encoder.blocks.5.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                encoder.blocks.5.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                encoder.blocks.5.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                  encoder.blocks.5.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 encoder.blocks.5.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.5.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   encoder.blocks.5.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     encoder.blocks.5.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   encoder.blocks.5.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     encoder.blocks.5.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  encoder.blocks.5.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    encoder.blocks.5.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                          encoder.ln_post.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                            encoder.ln_post.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.token_embedding.weight - [  512, 51865,     1], type =    f16 size =   101.30 MB ->    14.25 MB\n",
            "                                    decoder.positional_embedding - [  512,   448,     1], type =    f32 size =    0.875 MB\n",
            "                                decoder.blocks.0.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                              decoder.blocks.0.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                decoder.blocks.0.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.0.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                decoder.blocks.0.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.0.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                  decoder.blocks.0.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.0.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.0.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.0.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                        decoder.blocks.0.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                          decoder.blocks.0.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.0.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                          decoder.blocks.0.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.0.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                            decoder.blocks.0.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.0.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.0.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.0.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     decoder.blocks.0.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.0.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     decoder.blocks.0.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.0.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.0.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.1.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                              decoder.blocks.1.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                decoder.blocks.1.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.1.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                decoder.blocks.1.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.1.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                  decoder.blocks.1.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.1.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.1.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.1.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                        decoder.blocks.1.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                          decoder.blocks.1.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.1.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                          decoder.blocks.1.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.1.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                            decoder.blocks.1.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.1.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.1.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.1.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     decoder.blocks.1.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.1.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     decoder.blocks.1.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.1.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.1.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.2.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                              decoder.blocks.2.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                decoder.blocks.2.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.2.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                decoder.blocks.2.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.2.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                  decoder.blocks.2.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.2.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.2.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.2.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                        decoder.blocks.2.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                          decoder.blocks.2.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.2.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                          decoder.blocks.2.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.2.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                            decoder.blocks.2.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.2.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.2.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.2.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     decoder.blocks.2.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.2.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     decoder.blocks.2.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.2.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.2.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.3.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                              decoder.blocks.3.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                decoder.blocks.3.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.3.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                decoder.blocks.3.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.3.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                  decoder.blocks.3.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.3.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.3.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.3.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                        decoder.blocks.3.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                          decoder.blocks.3.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.3.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                          decoder.blocks.3.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.3.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                            decoder.blocks.3.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.3.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.3.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.3.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     decoder.blocks.3.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.3.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     decoder.blocks.3.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.3.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.3.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.4.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                              decoder.blocks.4.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                decoder.blocks.4.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.4.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                decoder.blocks.4.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.4.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                  decoder.blocks.4.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.4.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.4.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.4.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                        decoder.blocks.4.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                          decoder.blocks.4.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.4.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                          decoder.blocks.4.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.4.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                            decoder.blocks.4.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.4.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.4.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.4.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     decoder.blocks.4.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.4.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     decoder.blocks.4.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.4.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.4.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.5.attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                              decoder.blocks.5.attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                decoder.blocks.5.attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                              decoder.blocks.5.attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                decoder.blocks.5.attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                decoder.blocks.5.attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                                  decoder.blocks.5.attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                 decoder.blocks.5.attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.5.attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.5.cross_attn.key.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                        decoder.blocks.5.cross_attn.value.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                          decoder.blocks.5.cross_attn.value.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                        decoder.blocks.5.cross_attn.query.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                          decoder.blocks.5.cross_attn.query.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                          decoder.blocks.5.cross_attn.out.weight - [  512,   512,     1], type =    f16 size =     1.00 MB ->     0.14 MB\n",
            "                            decoder.blocks.5.cross_attn.out.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                           decoder.blocks.5.cross_attn_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                             decoder.blocks.5.cross_attn_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                   decoder.blocks.5.mlp.0.weight - [  512,  2048,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     decoder.blocks.5.mlp.0.bias - [ 2048,     1,     1], type =    f32 size =    0.008 MB\n",
            "                                   decoder.blocks.5.mlp.2.weight - [ 2048,   512,     1], type =    f16 size =     4.00 MB ->     0.56 MB\n",
            "                                     decoder.blocks.5.mlp.2.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                  decoder.blocks.5.mlp_ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                    decoder.blocks.5.mlp_ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                               decoder.ln.weight - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "                                                 decoder.ln.bias - [  512,     1,     1], type =    f32 size =    0.002 MB\n",
            "ggml_common_quantize_0: model size  =   276.92 MB\n",
            "ggml_common_quantize_0: quant size  =    43.76 MB | ftype = 2 (q4_0)\n",
            "\n",
            "main: quantize time =   900.27 ms\n",
            "main:    total time =   900.27 ms\n"
          ]
        }
      ],
      "source": [
        "!mkdir ./ggml-updated\n",
        "!python whisper.cpp/models/convert-h5-to-ggml.py ./final-model ./whisper-github ./ggml-updated\n",
        "\n",
        "# Quantize. See https://github.com/ggerganov/whisper.cpp/discussions/838\n",
        "!./whisper.cpp/build/bin/quantize ./ggml-updated/ggml-model.bin ./ggml-updated/ggml-model-q8_0.bin q8_0\n",
        "!./whisper.cpp/build/bin/quantize ./ggml-updated/ggml-model.bin ./ggml-updated/ggml-model-q5_0.bin q5_0\n",
        "!./whisper.cpp/build/bin/quantize ./ggml-updated/ggml-model.bin ./ggml-updated/ggml-model-q4_0.bin q4_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNKGqVn0zRg6"
      },
      "source": [
        "# Building the Joplin-compatible model\n",
        "\n",
        "Next, we need to convert the model to a format compatible with Joplin. A `.zip` file is created with the following structure:\n",
        "```\n",
        "model_name.zip/\n",
        "| model_name/\n",
        "| | README.md\n",
        "| | model.bin\n",
        "| | config.json\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucsOUrTqzRSz"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import shutil, json, zipfile\n",
        "\n",
        "def package_output(source_model: Path, output_dir: Path, output_filename: str):\n",
        "    if not output_dir.exists():\n",
        "        output_dir.mkdir()\n",
        "    unzipped_dir = output_dir / output_filename\n",
        "    if unzipped_dir.exists():\n",
        "        shutil.rmtree(unzipped_dir)\n",
        "    unzipped_dir.mkdir()\n",
        "\n",
        "    shutil.copyfile(source_model, unzipped_dir / 'model.bin')\n",
        "    # config.json\n",
        "    config_filepath = unzipped_dir / 'config.json'\n",
        "    config_filepath.write_text(json.dumps({\n",
        "        'prompts': {\n",
        "            # Custom prompts can improve accuracy.\n",
        "            'en': 'Joplin is a note-taking application. This is a Joplin note.'\n",
        "        },\n",
        "        # Performance: Informs Joplin that the model supports a shortened audio context\n",
        "        'shortAudioContext': True,\n",
        "        'output': {\n",
        "            '//': 'Each of the replacements is in the form [ original, replaceWith ]. For example, [\"test\", \"\"] replaces all instances of \"test\" with the empty string.',\n",
        "            'stringReplacements': [\n",
        "                [ '[BLANK_AUDIO]', '' ],\n",
        "            ],\n",
        "            'regexReplacements': [\n",
        "                [ r'^\\([^(),.?]+\\)$', ''],\n",
        "                [ r'^\\[[^(),.?]+\\]$', ''],\n",
        "                [ r'^[.,?!]$', '' ],\n",
        "                [ r'\\[swearB1\\]', 'BS' ],\n",
        "                [ r'\\[swear[A-Z][0-9]+\\]', '****' ],\n",
        "            ],\n",
        "        }\n",
        "    }, indent='\\t'))\n",
        "    # README.md\n",
        "    readme_filepath = unzipped_dir / 'README.md'\n",
        "    readme_filepath.write_text('\\n'.join([\n",
        "        '# {}'.format(output_filename),\n",
        "        '',\n",
        "        'This model is a version of `whisper-' + whisper_mode + '` with an [adjusted vocab.json](https://github.com/personalizedrefrigerator/joplin-voice-typing-test/blob/main/whisper_vocab_cleanup.ipynb) to reduce the probability of profanity when given noisy non-speech input.',\n",
        "        '',\n",
        "        'This model has also been [fine-tuned](https://github.com/joplin/voice-typing-models/blob/240c4de34b76aa516482f6e3155c19e14a414e37/whisper_more_efficient_encoding.ipynb) to improve efficiency.',\n",
        "        '',\n",
        "        '## License',\n",
        "        '',\n",
        "        'The Whisper model from which this is modified has the following license:',\n",
        "        '''\n",
        "        MIT License\n",
        "\n",
        "        Copyright (c) 2022 OpenAI\n",
        "\n",
        "        Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "        of this software and associated documentation files (the \"Software\"), to deal\n",
        "        in the Software without restriction, including without limitation the rights\n",
        "        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "        copies of the Software, and to permit persons to whom the Software is\n",
        "        furnished to do so, subject to the following conditions:\n",
        "\n",
        "        The above copyright notice and this permission notice shall be included in all\n",
        "        copies or substantial portions of the Software.\n",
        "\n",
        "        THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "        SOFTWARE.\n",
        "        ''',\n",
        "        '',\n",
        "        'The fine-tuning code that helped generate this model has the following license:',\n",
        "        '''\n",
        "        MIT License\n",
        "\n",
        "        Copyright (c) 2024 FUTO Organization\n",
        "\n",
        "        Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "        The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "        THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
        "\n",
        "        '''\n",
        "    ]))\n",
        "\n",
        "    # Make the .zip file\n",
        "    # See https://docs.python.org/3/library/shutil.html\n",
        "    shutil.make_archive(\n",
        "        output_dir / output_filename,\n",
        "        'zip',\n",
        "        root_dir=output_dir,\n",
        "        base_dir=output_filename,\n",
        "    )\n",
        "\n",
        "package_output(\n",
        "    Path('./ggml-updated/ggml-model.bin'),\n",
        "    Path('./joplin-model'),\n",
        "    'whisper-{}'.format(whisper_mode)\n",
        ")\n",
        "package_output(\n",
        "    Path('./ggml-updated/ggml-model-q8_0.bin'),\n",
        "    Path('./joplin-model-q8_0'),\n",
        "    'whisper-{}-q8_0'.format(whisper_mode)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCEyuCYi3Phx"
      },
      "source": [
        "The models are now built! They're stored in the `./joplin-model` and `./joplin-model-q8_0` directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knBgdcxbpdbw"
      },
      "outputs": [],
      "source": [
        "\n",
        "package_output(\n",
        "    Path('./ggml-updated/ggml-model-q5_0.bin'),\n",
        "    Path('./joplin-model-q5_0'),\n",
        "    'whisper-{}-q5_0'.format(whisper_mode)\n",
        ")\n",
        "package_output(\n",
        "    Path('./ggml-updated/ggml-model-q4_0.bin'),\n",
        "    Path('./joplin-model-q4_0'),\n",
        "    'whisper-{}-q4_0'.format(whisper_mode)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "razNbAnik9Um"
      },
      "source": [
        "## Google-colab-specific"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "O94RKzrZk8ud",
        "outputId": "a5b7764b-a191-4c36-93fa-8cea8903451d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e419fc64-7cdc-4cd3-b875-24e627a802be\", \"whisper-base.zip\", 131049372)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7d5641ab-9847-4926-8da9-fe096147940b\", \"whisper-base-q5_0.zip\", 45641556)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_64255aa9-0283-40f1-b4c1-0415aa4c3bc6\", \"whisper-base-q8_0.zip\", 72983587)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Google colab only: Save the files to the local machine\n",
        "from google.colab import files\n",
        "files.download(f'./joplin-model/whisper-{whisper_mode}.zip')\n",
        "files.download(f'./joplin-model-q5_0/whisper-{whisper_mode}-q5_0.zip')\n",
        "files.download(f'./joplin-model-q8_0/whisper-{whisper_mode}-q8_0.zip')\n",
        "files.download(f'./joplin-model-q4_0/whisper-{whisper_mode}-q4_0.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "000044775b1f49f8a11e60e5416df349": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "003a067cff2540cc8195faa83346befe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_805d48ee28434df09a9669f11b523e58",
              "IPY_MODEL_c8a06db1ca804d0f871fe1db2b3fa2a0",
              "IPY_MODEL_a2a98e0cb36f46b99e41a5da71382e7a"
            ],
            "layout": "IPY_MODEL_f2315f9f0f6942c9a9d84c5e7437e197"
          }
        },
        "03fc62205ec94f2b806028ccd64d161d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "044faa858eeb46329439ab91ce284a61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "059a8bc00e624e94a7a5b8d812929727": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ffaff647f9b494da09523525a6ab8a2",
            "placeholder": "​",
            "style": "IPY_MODEL_820c9a6e8ac546aa9bdd8470e4bf6b0b",
            "value": " 3193/0 [01:10&lt;00:00, 64.28 examples/s]"
          }
        },
        "076c81f2816343738e016caeb0cc3d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "090db7185c9549ba974bf9fa197d0b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09aa11f1ab4548269ca3fa7b55602043": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd872e7247049a5b4fadc57f9cd32ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d6e0f0da40b49e9ac71bf30ad89f0f1",
            "max": 13340,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48d89215af1449d9aa4837a7d72eb747",
            "value": 13340
          }
        },
        "0cd3bf7eb27b4ed8b1c9e0f0b86fd7c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2fb1039f0d46559c0e9d13d3c1899d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f2dccd4f7bd4c5ca2eded6080ef3822": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd065e67af446f493554e7a1405118a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106207d41f734a348143ef219e563ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39e036368b7d47b2861692a33c1f8d8d",
            "max": 2064047,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68f77267ab1c491a99c9e7287481e0e9",
            "value": 2064047
          }
        },
        "11424360c6894eef892cffff0f2d02d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a30b25ed607e442aaaae1da96cfc8fe4",
              "IPY_MODEL_0bd872e7247049a5b4fadc57f9cd32ee",
              "IPY_MODEL_a7c578a0e69146d3b5c75d53e4a225a3"
            ],
            "layout": "IPY_MODEL_ffb1b05b24dd442788c29a47196ff83e"
          }
        },
        "114f5e5d913a4c8c898d35cd25a7a091": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1206a503e9564738a14d4a9d4285c74c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12aa0fbf27b24354b20f2e57c02da162": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1310feab8b3f4424a5b5c9d5d38802ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "144596f8aaa84d7ea0163b01b3ebd1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16cc10de2cd645688f22b73373882789": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19cf3389474a48698a92832acee3f18f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b259bcf93574088821f5c6433cf5623": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_444dc1f65ba8410d9c67e75a73fe673c",
            "max": 34604,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39576e248ce54682a617643f2a9d947c",
            "value": 34604
          }
        },
        "1bb5faeb43eb41598b7cb553099d0667": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c3c094dbe6547aebd81da1994b21444": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ce2bc8952a44f1eb09c47c33f3ab24e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "206598dc996a4e53b42839d7b83721db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40cc98bdab7d48be992bc54aec13c870",
              "IPY_MODEL_62cdacb8df664b9eaaae2f288b35e5db",
              "IPY_MODEL_808674c965ea49beaf4e90a3ecb07375"
            ],
            "layout": "IPY_MODEL_d5c0562b4bfc42cc8ff81c3913a4b397"
          }
        },
        "20b2b12b877a4c83a87145aea1aea485": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59f1f07f18e04f20aacb7a3ae4e9c785",
            "max": 456972,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fffdaeb03a5f444c813f0a5d8f695275",
            "value": 456972
          }
        },
        "211dab2f2e474fa0b9342c8bb81b1b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23ee3e4bdd5046e8a187408b9fd709b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "259da823ae4146a0ba3d07cd61283e36": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25de75a6a6a849909df8f9964bbb3186": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d697e74ce5754ebca44cd0004d432e74",
              "IPY_MODEL_9e9aa5f1f62d43a2aa1bac3a7a370605",
              "IPY_MODEL_efd487ca0e0e4430b35cf4207eb84f85"
            ],
            "layout": "IPY_MODEL_03fc62205ec94f2b806028ccd64d161d"
          }
        },
        "276a68431bf148acabf621a65f42d70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2e457f67b914037a50ba239d05a4d54",
              "IPY_MODEL_74c132f9fe094fdeb9a40500ed631318",
              "IPY_MODEL_5ea4640bfd29456f882e008fde609976"
            ],
            "layout": "IPY_MODEL_cea9755b57e34ac582dd218030fbae40"
          }
        },
        "281e4ad469254ed8914f860caea86ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28803f5eb25d41ec9b4d264119c3a276": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a5e04b2c0744290a2950c6e1e672714": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2adec94e656c42c8858ab9c721ce27d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33fd50473c4048a0b16a44710fd29bdc",
              "IPY_MODEL_397baec41f6a4a9eb0f37df626fcb0bc",
              "IPY_MODEL_aacaddc20f22490e854b19d1c9ddef9c"
            ],
            "layout": "IPY_MODEL_19cf3389474a48698a92832acee3f18f"
          }
        },
        "2bafd2a7fe9e413d932370c71b50c7ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c8b6d0b734e45bd99673a89b95597df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ca950ef957a4a93a7ffc657915f4637": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c0e4d650dd346f2bbc172996e7b87d8",
            "placeholder": "​",
            "style": "IPY_MODEL_d0ac778cbf8c44e392910e0f1c95ec81",
            "value": "dev.tsv: 100%"
          }
        },
        "2ffaff647f9b494da09523525a6ab8a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "305f5b158d5a4172aa7c68a9f948ff9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "336e4ced31954f66bab02f7bc258b312": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33fd50473c4048a0b16a44710fd29bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_580dc0add5554e6cb2dddae2de0b1930",
            "placeholder": "​",
            "style": "IPY_MODEL_9882ddd4adb94c35a49b0c9ccb5e2e05",
            "value": "config.json: 100%"
          }
        },
        "3421b4bd291d4c4f93591de45683b776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34267202c4c94dde8ff5d87f1bc9d36f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "343cab84fabf4dc2a24909c68fce9787": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345ba32482574d1085a4f7a8ff1f92b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "354dd8d73a9b4991af1caa37f3b0337f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9018f8e0e9124f93bb081e5dca0f7bdc",
            "placeholder": "​",
            "style": "IPY_MODEL_51f7a3d2cb7744b5a2ffd63a074a4a6b",
            "value": "train.tsv: 100%"
          }
        },
        "35d2cd81332042b5a722f66539429513": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35d4218f504543b3a2d0b63993051be6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36118f96fa964df39e602e5eca6f3999": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9deaeef5294f42a59c5ed92b00ac333e",
            "placeholder": "​",
            "style": "IPY_MODEL_336e4ced31954f66bab02f7bc258b312",
            "value": "test.tar.gz: 100%"
          }
        },
        "36fd2666a3a2471a837438410700b312": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37ace24790444698b752c4968cd57346": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1206a503e9564738a14d4a9d4285c74c",
            "max": 180518,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58c868b18269426186b22cb2251c20d4",
            "value": 180518
          }
        },
        "395611b4037b47978c02ec24558d115a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c900c666b2ae434585ac1a46af8f61f8",
            "placeholder": "​",
            "style": "IPY_MODEL_4626d82323e04abea9568350663770f1",
            "value": " 457k/457k [00:00&lt;00:00, 20.3MB/s]"
          }
        },
        "39576e248ce54682a617643f2a9d947c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "397baec41f6a4a9eb0f37df626fcb0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09aa11f1ab4548269ca3fa7b55602043",
            "max": 1390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a43abd99dc4b4d50a1d37daad26da8dd",
            "value": 1390
          }
        },
        "39e036368b7d47b2861692a33c1f8d8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a57b6cb577344459d3d9dc3a231d8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7e5e4a3f0e44209824be75d6c13c096",
            "placeholder": "​",
            "style": "IPY_MODEL_c76a2ec583a640a58d1a8e4d3e2f383f",
            "value": " 676/0 [00:11&lt;00:00, 193.95 examples/s]"
          }
        },
        "3cf9f915d54049ec908ed6eb8aa4baca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40313219d9774f3791972231ac17b597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "409dc4ce6e38455fa740bd764abb77a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d49c74f861a47d0b4351feae527d5fc",
            "placeholder": "​",
            "style": "IPY_MODEL_b90896fa2b5847af942c29307a418fe2",
            "value": "fleurs.py: 100%"
          }
        },
        "40cc98bdab7d48be992bc54aec13c870": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16cc10de2cd645688f22b73373882789",
            "placeholder": "​",
            "style": "IPY_MODEL_bc80568500864ec888d113831e761cc8",
            "value": "generation_config.json: 100%"
          }
        },
        "444dc1f65ba8410d9c67e75a73fe673c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44694d5ac2d74cc59933ad3c94ae7c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4626d82323e04abea9568350663770f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48d89215af1449d9aa4837a7d72eb747": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "496b65a085ee48f7b38cd0ccc3f8c92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60bf454bb0f44d83a024ff8853d3c790",
            "placeholder": "​",
            "style": "IPY_MODEL_345ba32482574d1085a4f7a8ff1f92b4",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "49e71b73b773436d9cf1d49073cc9f54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab1fa6b92d848ec9b60b4088f6c8cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ce2fb8b0833489798e022601182530c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_929ccf3a803f434485d232d3a774a261",
            "placeholder": "​",
            "style": "IPY_MODEL_b31e6d5ebb2b4020b3d906a0d2cae2ea",
            "value": " 181k/181k [00:00&lt;00:00, 11.3MB/s]"
          }
        },
        "4cfff529177b4c2dba76f5e4b87f85e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d49c74f861a47d0b4351feae527d5fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d6abd0b8bde4970a4b5b248c3befb65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bfce4238a854cec8a0ebc7563ab1466",
              "IPY_MODEL_e73a4706663c44c5b5dbfa40ef73176a",
              "IPY_MODEL_d79a7608163347d69cd44fc126932f4e"
            ],
            "layout": "IPY_MODEL_12aa0fbf27b24354b20f2e57c02da162"
          }
        },
        "4e56620da0564341a94424f33914fe27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f76d415bb6d488eb67c083c21d3d5a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5018ffbb6e494b99b5b5da45d4256f60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "502092bb386c4b6a8dca1d52a7f7abed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9d57344050b4c40bc8203f02d227699",
            "placeholder": "​",
            "style": "IPY_MODEL_076c81f2816343738e016caeb0cc3d0d",
            "value": "test.tsv: 100%"
          }
        },
        "51dd52013dd8409fad7ddc7d93a91276": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51f7a3d2cb7744b5a2ffd63a074a4a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5341f8cf7d2145499e9491ae6985d4dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d7c97b4cdfc436caa0b7a9b229ad72c",
            "max": 12519,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51dd52013dd8409fad7ddc7d93a91276",
            "value": 12519
          }
        },
        "54035b97bb2941a3b8af459c9026abe9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5483dcc6e7f8446fbdf40e43acf85303": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb0e7dec3f8d40fe8580c3e47d8595fa",
              "IPY_MODEL_d3fbb333aed440b88061d195f2283ea8",
              "IPY_MODEL_5ffeb8f8a79d4a68b9e085c5a2ac2db7"
            ],
            "layout": "IPY_MODEL_49e71b73b773436d9cf1d49073cc9f54"
          }
        },
        "54e12e538a9e4090afb0f177dd89e663": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "580dc0add5554e6cb2dddae2de0b1930": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c868b18269426186b22cb2251c20d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "595dd6ac371e49d595a60dc7d41569ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_354dd8d73a9b4991af1caa37f3b0337f",
              "IPY_MODEL_106207d41f734a348143ef219e563ab4",
              "IPY_MODEL_ba2b2eb914234e3591d52cdaf561edc8"
            ],
            "layout": "IPY_MODEL_cace2bcffbe9435ea41f263c4cca1650"
          }
        },
        "5961316d0035449ab25f51fcc6593c60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59f1f07f18e04f20aacb7a3ae4e9c785": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b73d162c5464dcc8c301d6540217579": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bfce4238a854cec8a0ebc7563ab1466": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3a83bc8d51646f5b0948b25af11d227",
            "placeholder": "​",
            "style": "IPY_MODEL_be164dc3c4b34d0a9af2f831bf2d47e0",
            "value": "normalizer.json: 100%"
          }
        },
        "5d0608f4fd504c82a612dcd251f93f24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6e0f0da40b49e9ac71bf30ad89f0f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5da4930fe9174d9690d1c61a24bc6469": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ea4640bfd29456f882e008fde609976": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e2e6b777952497c86b1740a25a3518e",
            "placeholder": "​",
            "style": "IPY_MODEL_6504a871717944368599e3790364cf5e",
            "value": " 494k/494k [00:00&lt;00:00, 2.25MB/s]"
          }
        },
        "5f61e9ee10c5427794980b4c05b9c8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fd065e67af446f493554e7a1405118a",
            "placeholder": "​",
            "style": "IPY_MODEL_b1d05f93d4f545d1bf110c7d8239736f",
            "value": " 349M/349M [00:14&lt;00:00, 22.2MB/s]"
          }
        },
        "5fa56471c8404516b43732f1e9391991": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ffeb8f8a79d4a68b9e085c5a2ac2db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb6e4343c5b44d82ae8277a67349680d",
            "placeholder": "​",
            "style": "IPY_MODEL_d5c459fe58ca4653a2ac4ba807f92c04",
            "value": " 283k/283k [00:00&lt;00:00, 27.9MB/s]"
          }
        },
        "60bf454bb0f44d83a024ff8853d3c790": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e145eccfb24126b15987487f982b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d0608f4fd504c82a612dcd251f93f24",
            "max": 339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_691e91fee7044205a4f3d006876f8dd6",
            "value": 339
          }
        },
        "62cdacb8df664b9eaaae2f288b35e5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34267202c4c94dde8ff5d87f1bc9d36f",
            "max": 3753,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db43ff9a3bd34eaba0d7e30425e0475e",
            "value": 3753
          }
        },
        "631f8b5faae04e4cb90faf8233de9ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_928f754a226a49a3bf4574d05bd579f0",
            "placeholder": "​",
            "style": "IPY_MODEL_e4b1a65d3ff340a1bfe786b4831cc490",
            "value": " 12.5k/12.5k [00:00&lt;00:00, 1.35MB/s]"
          }
        },
        "647748b526d84bcf8df3f68eececc4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6504a871717944368599e3790364cf5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66777ae5da5f4616acb1e3ae247a3dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a3a38df40c4755aa5071ddfdcd25f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6745d7fb84644c119c6db9bd5caab455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdd56616fe3a45f19b38b083f16b464c",
            "max": 349036055,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_736fd825981f4922a35e93fff7b71436",
            "value": 349036055
          }
        },
        "68c33dd41b2446de8d7b834d6ee0cc3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68f77267ab1c491a99c9e7287481e0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "691e91fee7044205a4f3d006876f8dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6abc44816c0f41cc9c79e77abf6aed68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6c8be2bc89614dff8fe97fc321b4c3ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2f186b5ef5c4a6e959dd88e16791221",
              "IPY_MODEL_bc833dbb11564e24bb77b024963732af",
              "IPY_MODEL_ab198f92c218450f808bb91fc2312246"
            ],
            "layout": "IPY_MODEL_f4ef1d2453c5477e9c41662ed26a7830"
          }
        },
        "6d4bc9bf6f414a5f88db27206433f6c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d7c97b4cdfc436caa0b7a9b229ad72c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6db171d8bbb04583a3ca7bfe880e717d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35d2cd81332042b5a722f66539429513",
            "placeholder": "​",
            "style": "IPY_MODEL_305f5b158d5a4172aa7c68a9f948ff9c",
            "value": "model.safetensors: 100%"
          }
        },
        "6f80d5ee791647918d691a7506b1b6b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70c0b4822d014825a4a32e4803afd1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "736fd825981f4922a35e93fff7b71436": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74c132f9fe094fdeb9a40500ed631318": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c3f86ceef049f3b7d6ddce3e55b397",
            "max": 493869,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_647748b526d84bcf8df3f68eececc4e6",
            "value": 493869
          }
        },
        "78bc471e914d44e0b9f901d7c8210eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcd9a9b41b4b46bab7d19a0cc9c96eba",
              "IPY_MODEL_9cdc832d11f748eda802b2172e40088c",
              "IPY_MODEL_afff3f98438c4308ad52325706d5043b"
            ],
            "layout": "IPY_MODEL_3cf9f915d54049ec908ed6eb8aa4baca"
          }
        },
        "7a6affcb15d74eb5928fa00cecac3afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c6dd5ac3b1d4da1b8d4409aabb39b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f81113489325466e9ac0e1f927a6f3e5",
              "IPY_MODEL_d727170bdfc6453a8980ad5108febd92",
              "IPY_MODEL_3a57b6cb577344459d3d9dc3a231d8c2"
            ],
            "layout": "IPY_MODEL_b423b56bc2c7448381285e77bc557214"
          }
        },
        "7d49033f6cfa49bf979de9fdcfe219e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e2e6b777952497c86b1740a25a3518e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ec76f3b429c436dab661cab2acd75dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "805d48ee28434df09a9669f11b523e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb94912bda0c4486a675bdea98fa355f",
            "placeholder": "​",
            "style": "IPY_MODEL_68c33dd41b2446de8d7b834d6ee0cc3d",
            "value": "train.tar.gz: 100%"
          }
        },
        "808674c965ea49beaf4e90a3ecb07375": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ce2bc8952a44f1eb09c47c33f3ab24e",
            "placeholder": "​",
            "style": "IPY_MODEL_966877198a2c460b987a57eb181a11b0",
            "value": " 3.75k/3.75k [00:00&lt;00:00, 329kB/s]"
          }
        },
        "820c9a6e8ac546aa9bdd8470e4bf6b0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8370637b3a654933b33fa73f06ba5e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8704abdb0ea34e3d9c0a2e4638f0c562": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b6f093b8f294fb89c6cddc83bda94fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c0e4d650dd346f2bbc172996e7b87d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d7ef8017dff4dfeb65763505a15521f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9018f8e0e9124f93bb081e5dca0f7bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91816269aaea4d028af7c2b060220eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ca950ef957a4a93a7ffc657915f4637",
              "IPY_MODEL_37ace24790444698b752c4968cd57346",
              "IPY_MODEL_4ce2fb8b0833489798e022601182530c"
            ],
            "layout": "IPY_MODEL_9c38caa03b3844b48631c0dcc310eab5"
          }
        },
        "928f754a226a49a3bf4574d05bd579f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929ccf3a803f434485d232d3a774a261": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95ca694f743041c497932b40257ea93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "966877198a2c460b987a57eb181a11b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97929a40a7f3476cb41d8d2029c72b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5018ffbb6e494b99b5b5da45d4256f60",
            "placeholder": "​",
            "style": "IPY_MODEL_5fa56471c8404516b43732f1e9391991",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9882ddd4adb94c35a49b0c9ccb5e2e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9972321dede143afa4772c4ea4df8a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aca1f1e0e3b4285823c36f27e74f343": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5961316d0035449ab25f51fcc6593c60",
            "placeholder": "​",
            "style": "IPY_MODEL_fe9f4c1a578c4e7a99339c8ca362807a",
            "value": " 339/339 [00:00&lt;00:00, 40.4kB/s]"
          }
        },
        "9c38caa03b3844b48631c0dcc310eab5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cdc832d11f748eda802b2172e40088c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f108d35a1a0242498628fe0947dc03bb",
            "max": 142638560,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54e12e538a9e4090afb0f177dd89e663",
            "value": 142638560
          }
        },
        "9d598e6925564e79b370922a84216131": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9deaeef5294f42a59c5ed92b00ac333e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e7e861ab78e4239a73aa31c0186343d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_409dc4ce6e38455fa740bd764abb77a9",
              "IPY_MODEL_5341f8cf7d2145499e9491ae6985d4dc",
              "IPY_MODEL_631f8b5faae04e4cb90faf8233de9ebb"
            ],
            "layout": "IPY_MODEL_d1046e2c049043eeb0b89273d0202f7d"
          }
        },
        "9e9aa5f1f62d43a2aa1bac3a7a370605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6abc44816c0f41cc9c79e77abf6aed68",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdb764b247104c7e97a87becb7bac18b",
            "value": 1
          }
        },
        "9fbb57c244c54c748e6ec0fd4244abd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_114f5e5d913a4c8c898d35cd25a7a091",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23ee3e4bdd5046e8a187408b9fd709b5",
            "value": 1
          }
        },
        "a22341bcfea44498a74cb09df9ef5ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a98e0cb36f46b99e41a5da71382e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a5e04b2c0744290a2950c6e1e672714",
            "placeholder": "​",
            "style": "IPY_MODEL_5da4930fe9174d9690d1c61a24bc6469",
            "value": " 1.73G/1.73G [00:26&lt;00:00, 22.9MB/s]"
          }
        },
        "a30b25ed607e442aaaae1da96cfc8fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f80d5ee791647918d691a7506b1b6b5",
            "placeholder": "​",
            "style": "IPY_MODEL_2c8b6d0b734e45bd99673a89b95597df",
            "value": "README.md: 100%"
          }
        },
        "a43abd99dc4b4d50a1d37daad26da8dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4bf322c91004959adbb5e53d4d06084": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7c578a0e69146d3b5c75d53e4a225a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d49033f6cfa49bf979de9fdcfe219e7",
            "placeholder": "​",
            "style": "IPY_MODEL_8370637b3a654933b33fa73f06ba5e8a",
            "value": " 13.3k/13.3k [00:00&lt;00:00, 1.32MB/s]"
          }
        },
        "aacaddc20f22490e854b19d1c9ddef9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da1041d342934bcebad5d2eaf8339d82",
            "placeholder": "​",
            "style": "IPY_MODEL_36fd2666a3a2471a837438410700b312",
            "value": " 1.39k/1.39k [00:00&lt;00:00, 98.4kB/s]"
          }
        },
        "ab198f92c218450f808bb91fc2312246": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2eacf952bab4dc18c8e85284d6986db",
            "placeholder": "​",
            "style": "IPY_MODEL_40313219d9774f3791972231ac17b597",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 14.9MB/s]"
          }
        },
        "adadfa51380245998d64477dc7518231": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ec76f3b429c436dab661cab2acd75dd",
            "placeholder": "​",
            "style": "IPY_MODEL_8d7ef8017dff4dfeb65763505a15521f",
            "value": " 290M/290M [00:01&lt;00:00, 318MB/s]"
          }
        },
        "afff3f98438c4308ad52325706d5043b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0d82edf9f9c45a78ec0e3b9e14a1c5b",
            "placeholder": "​",
            "style": "IPY_MODEL_6d4bc9bf6f414a5f88db27206433f6c8",
            "value": " 143M/143M [00:05&lt;00:00, 24.6MB/s]"
          }
        },
        "b1d05f93d4f545d1bf110c7d8239736f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b31e6d5ebb2b4020b3d906a0d2cae2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b423b56bc2c7448381285e77bc557214": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e8aa4e3e4241558fca50c3822f878c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6db171d8bbb04583a3ca7bfe880e717d",
              "IPY_MODEL_d1ee213274a84336a6b6db12c0439a32",
              "IPY_MODEL_adadfa51380245998d64477dc7518231"
            ],
            "layout": "IPY_MODEL_2bafd2a7fe9e413d932370c71b50c7ef"
          }
        },
        "b75809adbbc249d9a8fbf0d8796254fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c07b7c80b4294f358d7bb7e8e273d581",
            "placeholder": "​",
            "style": "IPY_MODEL_9972321dede143afa4772c4ea4df8a43",
            "value": "added_tokens.json: 100%"
          }
        },
        "b7e5e4a3f0e44209824be75d6c13c096": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b90896fa2b5847af942c29307a418fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9d57344050b4c40bc8203f02d227699": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba2b2eb914234e3591d52cdaf561edc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cd3bf7eb27b4ed8b1c9e0f0b86fd7c5",
            "placeholder": "​",
            "style": "IPY_MODEL_144596f8aaa84d7ea0163b01b3ebd1fd",
            "value": " 2.06M/2.06M [00:00&lt;00:00, 23.5MB/s]"
          }
        },
        "bb03d54238a44541968dc8617081c898": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_502092bb386c4b6a8dca1d52a7f7abed",
              "IPY_MODEL_20b2b12b877a4c83a87145aea1aea485",
              "IPY_MODEL_395611b4037b47978c02ec24558d115a"
            ],
            "layout": "IPY_MODEL_343cab84fabf4dc2a24909c68fce9787"
          }
        },
        "bb6e4343c5b44d82ae8277a67349680d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc80568500864ec888d113831e761cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc833dbb11564e24bb77b024963732af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66777ae5da5f4616acb1e3ae247a3dc0",
            "max": 1036584,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d575a57f365b4fb4b5e1198ff8cbaf4a",
            "value": 1036584
          }
        },
        "bdb764b247104c7e97a87becb7bac18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdd56616fe3a45f19b38b083f16b464c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be164dc3c4b34d0a9af2f831bf2d47e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c07b7c80b4294f358d7bb7e8e273d581": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c3f86ceef049f3b7d6ddce3e55b397": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a881b74f804579a0de940910f86297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c757dc0183354d7a954985d6a5c684d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c76a2ec583a640a58d1a8e4d3e2f383f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8a06db1ca804d0f871fe1db2b3fa2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_259da823ae4146a0ba3d07cd61283e36",
            "max": 1730529959,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce1a67c37d1041878aaa621889ac78ce",
            "value": 1730529959
          }
        },
        "c900c666b2ae434585ac1a46af8f61f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cace2bcffbe9435ea41f263c4cca1650": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb0e7dec3f8d40fe8580c3e47d8595fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4e5ba25a5ea482f9afea5a9c1cca51f",
            "placeholder": "​",
            "style": "IPY_MODEL_ddb879a1eaa34af298efbcb08c6c8cbc",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "cb94912bda0c4486a675bdea98fa355f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce1a67c37d1041878aaa621889ac78ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cea9755b57e34ac582dd218030fbae40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ac778cbf8c44e392910e0f1c95ec81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1046e2c049043eeb0b89273d0202f7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1ee213274a84336a6b6db12c0439a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d291796f399b4b00a474af019ff16291",
            "max": 290403936,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f97076eef7134d1996cf841c0ee29575",
            "value": 290403936
          }
        },
        "d291796f399b4b00a474af019ff16291": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2eacf952bab4dc18c8e85284d6986db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3fbb333aed440b88061d195f2283ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8704abdb0ea34e3d9c0a2e4638f0c562",
            "max": 282713,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f00040648afc4d49899dd7b14d72acc2",
            "value": 282713
          }
        },
        "d575a57f365b4fb4b5e1198ff8cbaf4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5c0562b4bfc42cc8ff81c3913a4b397": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5c459fe58ca4653a2ac4ba807f92c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d697e74ce5754ebca44cd0004d432e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db5d106524be442baa9289544aa2e14b",
            "placeholder": "​",
            "style": "IPY_MODEL_95ca694f743041c497932b40257ea93d",
            "value": "Generating validation split: "
          }
        },
        "d727170bdfc6453a8980ad5108febd92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66a3a38df40c4755aa5071ddfdcd25f9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3421b4bd291d4c4f93591de45683b776",
            "value": 1
          }
        },
        "d79a7608163347d69cd44fc126932f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_000044775b1f49f8a11e60e5416df349",
            "placeholder": "​",
            "style": "IPY_MODEL_c5a881b74f804579a0de940910f86297",
            "value": " 52.7k/52.7k [00:00&lt;00:00, 5.26MB/s]"
          }
        },
        "d9fc5fb5ed1049549dbe5c48e4d2acb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54035b97bb2941a3b8af459c9026abe9",
            "placeholder": "​",
            "style": "IPY_MODEL_a4bf322c91004959adbb5e53d4d06084",
            "value": " 34.6k/34.6k [00:00&lt;00:00, 3.14MB/s]"
          }
        },
        "da1041d342934bcebad5d2eaf8339d82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db43ff9a3bd34eaba0d7e30425e0475e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db5d106524be442baa9289544aa2e14b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd9a9b41b4b46bab7d19a0cc9c96eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c757dc0183354d7a954985d6a5c684d1",
            "placeholder": "​",
            "style": "IPY_MODEL_7a6affcb15d74eb5928fa00cecac3afc",
            "value": "dev.tar.gz: 100%"
          }
        },
        "ddb879a1eaa34af298efbcb08c6c8cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e095966878f34e0eb8b24eb7707e9576": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_044faa858eeb46329439ab91ce284a61",
            "max": 2194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70c0b4822d014825a4a32e4803afd1b0",
            "value": 2194
          }
        },
        "e0d82edf9f9c45a78ec0e3b9e14a1c5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28a670a4fff4bf9b54653062926a747": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_496b65a085ee48f7b38cd0ccc3f8c92a",
              "IPY_MODEL_60e145eccfb24126b15987487f982b51",
              "IPY_MODEL_9aca1f1e0e3b4285823c36f27e74f343"
            ],
            "layout": "IPY_MODEL_44694d5ac2d74cc59933ad3c94ae7c6d"
          }
        },
        "e2e457f67b914037a50ba239d05a4d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_281e4ad469254ed8914f860caea86ba6",
            "placeholder": "​",
            "style": "IPY_MODEL_4ab1fa6b92d848ec9b60b4088f6c8cdc",
            "value": "merges.txt: 100%"
          }
        },
        "e2f186b5ef5c4a6e959dd88e16791221": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e2fb1039f0d46559c0e9d13d3c1899d",
            "placeholder": "​",
            "style": "IPY_MODEL_1310feab8b3f4424a5b5c9d5d38802ec",
            "value": "vocab.json: 100%"
          }
        },
        "e32d9d601608434684a5d92084ebd771": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b73d162c5464dcc8c301d6540217579",
            "placeholder": "​",
            "style": "IPY_MODEL_090db7185c9549ba974bf9fa197d0b87",
            "value": "Generating train split: "
          }
        },
        "e3a83bc8d51646f5b0948b25af11d227": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3dfd8fbb52040b1ae45f8233250d18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e32d9d601608434684a5d92084ebd771",
              "IPY_MODEL_9fbb57c244c54c748e6ec0fd4244abd4",
              "IPY_MODEL_059a8bc00e624e94a7a5b8d812929727"
            ],
            "layout": "IPY_MODEL_35d4218f504543b3a2d0b63993051be6"
          }
        },
        "e4b1a65d3ff340a1bfe786b4831cc490": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e73a4706663c44c5b5dbfa40ef73176a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f76d415bb6d488eb67c083c21d3d5a2",
            "max": 52666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bb5faeb43eb41598b7cb553099d0667",
            "value": 52666
          }
        },
        "e9496db797a346eebda36905100595b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36118f96fa964df39e602e5eca6f3999",
              "IPY_MODEL_6745d7fb84644c119c6db9bd5caab455",
              "IPY_MODEL_5f61e9ee10c5427794980b4c05b9c8d1"
            ],
            "layout": "IPY_MODEL_28803f5eb25d41ec9b4d264119c3a276"
          }
        },
        "eb626516bbdd4bf49dc4c64732d69d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d598e6925564e79b370922a84216131",
            "placeholder": "​",
            "style": "IPY_MODEL_4e56620da0564341a94424f33914fe27",
            "value": " 2.19k/2.19k [00:00&lt;00:00, 191kB/s]"
          }
        },
        "efd487ca0e0e4430b35cf4207eb84f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c3c094dbe6547aebd81da1994b21444",
            "placeholder": "​",
            "style": "IPY_MODEL_4cfff529177b4c2dba76f5e4b87f85e4",
            "value": " 289/0 [00:02&lt;00:00, 190.77 examples/s]"
          }
        },
        "f00040648afc4d49899dd7b14d72acc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f108d35a1a0242498628fe0947dc03bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2315f9f0f6942c9a9d84c5e7437e197": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4e5ba25a5ea482f9afea5a9c1cca51f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ef1d2453c5477e9c41662ed26a7830": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f81113489325466e9ac0e1f927a6f3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b6f093b8f294fb89c6cddc83bda94fc",
            "placeholder": "​",
            "style": "IPY_MODEL_211dab2f2e474fa0b9342c8bb81b1b05",
            "value": "Generating test split: "
          }
        },
        "f97076eef7134d1996cf841c0ee29575": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd54e14b28264c19800a891e1c5f763d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b75809adbbc249d9a8fbf0d8796254fd",
              "IPY_MODEL_1b259bcf93574088821f5c6433cf5623",
              "IPY_MODEL_d9fc5fb5ed1049549dbe5c48e4d2acb8"
            ],
            "layout": "IPY_MODEL_0f2dccd4f7bd4c5ca2eded6080ef3822"
          }
        },
        "fdfedeeedfc244578d20f67901ac832c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97929a40a7f3476cb41d8d2029c72b13",
              "IPY_MODEL_e095966878f34e0eb8b24eb7707e9576",
              "IPY_MODEL_eb626516bbdd4bf49dc4c64732d69d45"
            ],
            "layout": "IPY_MODEL_a22341bcfea44498a74cb09df9ef5ec6"
          }
        },
        "fe9f4c1a578c4e7a99339c8ca362807a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffb1b05b24dd442788c29a47196ff83e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fffdaeb03a5f444c813f0a5d8f695275": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
